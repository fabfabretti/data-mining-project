{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 3 - Sequence tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "# Takes a timedelta and prints it in a human-readable format.\n",
    "def format_timedelta(td: timedelta) -> str:\n",
    "    days = td.days\n",
    "    years, days = divmod(days, 365)\n",
    "    months, days = divmod(days, 30)\n",
    "    hours, remainder = divmod(td.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    formatted_str = \"\"\n",
    "    if years:\n",
    "        formatted_str += f\"{years}y \"\n",
    "    if months:\n",
    "        formatted_str += f\"{months}mo \"\n",
    "    if days:\n",
    "        formatted_str += f\"{days}d \"\n",
    "    if hours:\n",
    "        formatted_str += f\"{hours}h \"\n",
    "    if minutes:\n",
    "        formatted_str += f\"{minutes}m \"\n",
    "    if seconds:\n",
    "        formatted_str += f\"{seconds}s \"\n",
    "    \n",
    "\n",
    "    \n",
    "    return formatted_str[:-1] if formatted_str else \"0s\"\n",
    "  \n",
    "# Given a set with binary classes, computes entropy\n",
    "def compute_entropy(dataset_Y):\n",
    "    ones = len(list(filter(lambda classification : classification == 1,dataset_Y)))\n",
    "    zeros = len(list(filter(lambda classification : classification == -1,dataset_Y)))\n",
    "\n",
    "    if(ones == 0 or zeros==0):\n",
    "        return 0\n",
    "    \n",
    "    entropy = ones/len(dataset_Y)*math.log2(1/(ones/len(dataset_Y))) + zeros/len(dataset_Y)*math.log2(1/(zeros/len(dataset_Y)))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "# returns a list of tuples (i,x) where i is the index of the patient in the dataset and x is a timedelta of per quanto tempo abbiamo rilevazioni\n",
    "def find_durations(dataset):\n",
    "    lengths = []\n",
    "    for entry in dataset:\n",
    "        min_t = datetime.max\n",
    "        max_t = datetime.min\n",
    "        for item in entry:\n",
    "            if item[0] < min_t:\n",
    "                min_t = item[0]\n",
    "            elif item[0] > max_t:\n",
    "                max_t = item[0]\n",
    "        lengths.append(max_t-min_t)\n",
    "    return [(i, x) for i, x in enumerate(lengths)]\n",
    "\n",
    "# Find al possible d,l couples that I could split the tree on. Note: Ds are randomly/evenly selected bc otherwise I'd end up with ~36000 pairs...\n",
    "def create_pairs(dataset_X:list,dataset_ST:list,howmany_d =30,random_sampling=False):\n",
    "\n",
    "    #1. Create all labels available from current\n",
    "    labels = set()\n",
    "    for i in range(0,len(dataset_X)):\n",
    "        for item in dataset_X[i]:\n",
    "            if (item[0] > dataset_ST[i]):# Only consider label if it's not been superato\n",
    "                labels.add(item[1])\n",
    "\n",
    "\n",
    "    #2. Find all d\n",
    "    durations = set()\n",
    "    if random_sampling:\n",
    "        durations = set()\n",
    "        for i in range(0,len(dataset_X)):\n",
    "            for item in dataset_X[i]:\n",
    "                if (item[0] > dataset_ST[i]): # Only consider timestamp if it's not been superato\n",
    "                    durations.add(item[0]-dataset_ST[i])\n",
    "        if len(durations)>howmany_d:\n",
    "            durations = random.sample(sorted(durations),howmany_d) # Is this ok?\n",
    "        else:\n",
    "            durations = sorted(durations)\n",
    "    else:\n",
    "        durations = set()\n",
    "        for i in range(0,len(dataset_X)):\n",
    "            for item in dataset_X[i]:\n",
    "                durations.add(item[0]-dataset_ST[i])\n",
    "        delta = max(durations)/(howmany_d+1)\n",
    "        durations = set()\n",
    "        for i in range(1,howmany_d+1):\n",
    "            durations.add(delta*i)\n",
    "\n",
    "    return sorted(list(itertools.product(durations,labels)))\n",
    "\n",
    "# Given a d,l couple, split the dataset and return indexes of true and false entries.\n",
    "def test_event(dataset_X,dl_pair,dataset_ST):\n",
    "    i_T = [] # indexes of entries that have label==l within d time\n",
    "    i_F = [] # indexes of entries that have DON'T HAVE label==l within d time\n",
    "    d,l = dl_pair\n",
    "\n",
    "\n",
    "    #1. Separate entries that satisfy event test from those who don't\n",
    "    for i in range(0,len(dataset_X)):\n",
    "        entry = dataset_X[i]\n",
    "        found=False\n",
    "\n",
    "        for item in entry:\n",
    "            #print(item)\n",
    "            if(found is False and item[0]>=dataset_ST[i] and item[0]<=(dataset_ST[i]+d) and item[1]==l ):\n",
    "                found=True\n",
    "\n",
    "        if(found):\n",
    "            i_T.append(i)\n",
    "        else:\n",
    "            i_F.append(i)\n",
    "    return i_T,i_F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and parsing DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DS loader\n",
      "\tSkipped 46 items for formatting issues in data file. 70 loaded.\n",
      "-- DS builder\n",
      "\t6 entries unsuitable for selected windows.\n",
      "\tFinal dataset size: 64. Classes: 27|37, entropy  0.0\n",
      "--DS state\n",
      "index\tX\tY\tST\t\t\tV \n",
      "0\tl.35\t1\t1991-04-21 09:09:00\tNone\tfile=\n",
      "1\tl.38\t0\t1989-10-10 08:00:00\tNone\tfile=\n",
      "2\tl.49\t1\t1990-07-21 06:43:00\tNone\tfile=\n",
      "3\tl.41\t0\t1990-08-19 17:00:00\tNone\tfile=\n",
      "4\tl.46\t0\t1990-09-01 16:48:00\tNone\tfile=\n",
      "5\tl.38\t0\t1989-03-27 22:00:00\tNone\tfile=\n",
      "6\tl.24\t1\t1990-07-31 12:09:00\tNone\tfile=\n",
      "7\tl.43\t0\t1990-04-22 18:08:00\tNone\tfile=\n",
      "8\tl.34\t0\t1989-02-18 08:00:00\tNone\tfile=\n",
      "9\tl.34\t1\t1990-07-13 09:44:00\tNone\tfile=\n",
      "10\tl.46\t1\t1990-07-22 09:53:00\tNone\tfile=\n",
      "11\tl.58\t1\t1990-09-04 05:53:00\tNone\tfile=\n",
      "12\tl.38\t1\t1991-03-11 18:15:00\tNone\tfile=\n",
      "13\tl.27\t1\t1991-04-13 08:47:00\tNone\tfile=\n",
      "14\tl.22\t1\t1991-05-22 07:24:00\tNone\tfile=\n",
      "15\tl.40\t1\t1990-07-13 09:48:00\tNone\tfile=\n",
      "16\tl.44\t0\t1990-08-18 07:16:00\tNone\tfile=\n",
      "17\tl.45\t1\t1990-09-09 17:23:00\tNone\tfile=\n",
      "18\tl.39\t0\t1991-05-12 06:55:00\tNone\tfile=\n",
      "19\tl.44\t0\t1989-09-03 08:00:00\tNone\tfile=\n",
      "20\tl.36\t0\t1991-03-14 22:05:00\tNone\tfile=\n",
      "21\tl.37\t0\t1991-04-27 23:02:00\tNone\tfile=\n",
      "22\tl.28\t0\t1991-05-28 21:35:00\tNone\tfile=\n",
      "23\tl.13\t0\t1990-07-24 16:00:00\tNone\tfile=\n",
      "24\tl.25\t0\t1988-07-13 08:00:00\tNone\tfile=\n",
      "25\tl.16\t0\t1989-01-29 08:00:00\tNone\tfile=\n",
      "26\tl.16\t0\t1989-11-05 07:00:00\tNone\tfile=\n",
      "27\tl.40\t0\t1990-04-29 07:00:00\tNone\tfile=\n",
      "28\tl.40\t0\t1990-12-18 07:00:00\tNone\tfile=\n",
      "29\tl.39\t0\t1991-05-20 08:00:00\tNone\tfile=\n",
      "30\tl.65\t1\t1990-07-31 18:28:00\tNone\tfile=\n",
      "31\tl.45\t1\t1990-08-23 07:19:00\tNone\tfile=\n",
      "32\tl.52\t1\t1990-09-11 18:00:00\tNone\tfile=\n",
      "33\tl.10\t1\t1991-03-28 15:35:00\tNone\tfile=\n",
      "34\tl.47\t1\t1991-04-26 06:17:00\tNone\tfile=\n",
      "35\tl.55\t0\t1991-06-11 18:05:00\tNone\tfile=\n",
      "36\tl.49\t0\t1991-07-03 12:21:00\tNone\tfile=\n",
      "37\tl.39\t0\t1990-12-16 08:00:00\tNone\tfile=\n",
      "38\tl.41\t0\t1991-06-30 08:00:00\tNone\tfile=\n",
      "39\tl.52\t1\t1990-07-13 11:36:00\tNone\tfile=\n",
      "40\tl.53\t1\t1990-08-26 17:26:00\tNone\tfile=\n",
      "41\tl.51\t1\t1990-09-13 20:56:00\tNone\tfile=\n",
      "42\tl.48\t0\t1991-03-29 18:59:00\tNone\tfile=\n",
      "43\tl.52\t1\t1991-05-04 01:05:00\tNone\tfile=\n",
      "44\tl.39\t1\t1991-07-05 20:47:00\tNone\tfile=\n",
      "45\tl.36\t1\t1990-07-16 11:40:00\tNone\tfile=\n",
      "46\tl.28\t0\t1990-08-03 06:31:00\tNone\tfile=\n",
      "47\tl.45\t0\t1991-03-30 05:56:00\tNone\tfile=\n",
      "48\tl.39\t0\t1991-04-20 11:20:00\tNone\tfile=\n",
      "49\tl.35\t0\t1989-03-28 08:00:00\tNone\tfile=\n",
      "50\tl.39\t0\t1990-07-29 07:00:00\tNone\tfile=\n",
      "51\tl.41\t0\t1991-03-01 08:00:00\tNone\tfile=\n",
      "52\tl.47\t0\t1989-02-03 08:00:00\tNone\tfile=\n",
      "53\tl.22\t0\t1990-06-25 19:16:00\tNone\tfile=\n",
      "54\tl.54\t1\t1990-08-22 05:29:00\tNone\tfile=\n",
      "55\tl.59\t1\t1990-09-04 05:35:00\tNone\tfile=\n",
      "56\tl.56\t0\t1991-04-15 13:08:00\tNone\tfile=\n",
      "57\tl.43\t0\t1991-05-16 20:40:00\tNone\tfile=\n",
      "58\tl.48\t0\t1991-06-12 05:48:00\tNone\tfile=\n",
      "59\tl.45\t1\t1991-07-26 22:04:00\tNone\tfile=\n",
      "60\tl.40\t1\t1989-04-17 06:35:00\tNone\tfile=\n",
      "61\tl.40\t1\t1991-01-01 09:10:00\tNone\tfile=\n",
      "62\tl.12\t0\t1988-03-27 08:00:00\tNone\tfile=\n",
      "63\tl.30\t0\t1989-03-13 08:00:00\tNone\tfile=\n",
      "# entries: 64, entropy= 0.0\n"
     ]
    }
   ],
   "source": [
    "def load_diabetes_dataset(verbose=False)-> list: \n",
    "    folder_path=\"datasets\\\\diabetes\"\n",
    "    dataset = []\n",
    "    errcount=0\n",
    "    print(f\"-- DS loader\")\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path)and filename.startswith('data'):\n",
    "            entry=[]\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.readlines()\n",
    "                for line in content:\n",
    "                    item = tuple((line[0:-1] if line.endswith('\\n') else tuple(line)).split(\"\\t\"))\n",
    "\n",
    "                    # If the item is valid, append it to the entry\n",
    "                    try:\n",
    "                        item_f = datetime.strptime(item[0]+\" \"+item[1], \"%m-%d-%Y %H:%M\")\n",
    "                        entry.append((item_f,item[2],item[3]))\n",
    "                    except:\n",
    "                        if(verbose):\n",
    "                            print(f\"\\t[!] Entry {item} in file {filename} is NOT vallid. Skipped!\")\n",
    "                        errcount+=1\n",
    "                # add the entry to the dataset\n",
    "                dataset.append(entry)\n",
    "    print(f\"\\tSkipped {errcount} items for formatting issues in data file. {len(dataset)} loaded.\")\n",
    "    return dataset\n",
    "\n",
    "def compute_datasets(dataset:list,observation_window,waiting_window,prediction_window):\n",
    "\n",
    "    dataset_X = []\n",
    "    dataset_Y = []\n",
    "    \n",
    "    dataset_ST = [entry[0][0] for entry in dataset ]\n",
    "\n",
    "    count_excluded=0\n",
    "\n",
    "    for i in range(0,len(dataset)):\n",
    "        entry = dataset[i]\n",
    "\n",
    "        end_obs = dataset_ST[i]+observation_window\n",
    "        \n",
    "        start_pred = end_obs + waiting_window\n",
    "        end_pred = start_pred + prediction_window\n",
    "\n",
    "        if end_pred < entry[-1][0]:\n",
    "            entry_X = []\n",
    "            found = 0\n",
    "\n",
    "            for item in entry:\n",
    "                if item[0]>= dataset_ST[i] and item[0]<end_obs:\n",
    "                    entry_X.append(item)\n",
    "                if item[0]>=start_pred and item[0]<end_pred:\n",
    "                    # put Y=1 if it has at least one \"65\" entry\n",
    "                    if (item[1]==\"65\"):\n",
    "                        found = 1\n",
    "            dataset_X.append(entry_X)\n",
    "            dataset_Y.append(found)\n",
    "\n",
    "        else:\n",
    "            count_excluded+=1\n",
    "    \n",
    "    dataset_ST = [entry[0][0] for entry in dataset_X ]\n",
    "    dataset_V = [None]*len(dataset_X)\n",
    "    print(f\"-- DS builder\")\n",
    "    print(f\"\\t{count_excluded} entries unsuitable for selected windows.\")\n",
    "    print(f\"\\tFinal dataset size: {len(dataset_X)}. Classes: {sum(1 for c in dataset_Y if c == 1)}|{sum(1 for c in dataset_Y if c == 0)}, entropy {float(compute_entropy(dataset_Y)):4.3}\")    \n",
    "    return dataset_X,dataset_Y,dataset_ST,dataset_V\n",
    "\n",
    "# Quick reload if needed for testing/showcasing purposes\n",
    "def reload_ds():\n",
    "    # prepare\n",
    "    dataset = load_diabetes_dataset(False)\n",
    "    observation_window = timedelta(days=+3)\n",
    "    waiting_window = timedelta(days=+0)\n",
    "    prediction_window = timedelta(days=+10)\n",
    "\n",
    "    dataset_X,dataset_Y, dataset_ST,dataset_V = compute_datasets(dataset,observation_window,waiting_window,prediction_window,)\n",
    "    return dataset_X[:-1],dataset_Y[:-1], dataset_ST[:-1],dataset_V[:-1]\n",
    "\n",
    "def print_dataset_state(dataset_X,dataset_Y,dataset_ST,dataset_V,dataset_W=None,indexes=None):\n",
    "    print(\"--DS state\")\n",
    "    if (indexes and len(indexes)>len(dataset_X)):\n",
    "        indexes=None\n",
    "    \n",
    "    \n",
    "    print(\"index\\tX\\tY\\tST\\t\\t\\tV\",\"\\tW\" if dataset_W else \"\")\n",
    "\n",
    "    if indexes is None:\n",
    "        indexes = range(0,len(dataset_X))\n",
    "\n",
    "    for i in indexes:\n",
    "        print(f\"{i}\\tl.{len(dataset_X[i])}\\t{dataset_Y[i]}\\t{dataset_ST[i]}\\t{dataset_V[i]}\\t{dataset_W[i] if dataset_W else \"file=\"}\",)\n",
    "    print(f\"# entries: {len(dataset_X)}, entropy={float(compute_entropy(dataset_Y)):4.3}\")\n",
    "    \n",
    "\n",
    "dataset = load_diabetes_dataset(False)\n",
    "\n",
    "observation_window = timedelta(days=+5)\n",
    "waiting_window = timedelta(days=+5)\n",
    "prediction_window = timedelta(days=+15)\n",
    "\n",
    "# Convert raw data into dataset X,Y, etc\n",
    "dataset_X,dataset_Y, dataset_ST,dataset_V = compute_datasets(dataset[:],observation_window,waiting_window,prediction_window)\n",
    "print_dataset_state(dataset_X,dataset_Y, dataset_ST,dataset_V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequenceTree definition and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Tree,Node\n",
    "\n",
    "class SequenceTrunk(Tree):\n",
    "\n",
    "    #  -- FUNDAMENTALS\n",
    "\n",
    "    def __init__(self, tree=None, deep=False, node_class=None, identifier=None):\n",
    "        super(SequenceTrunk, self).__init__(tree=tree, deep=deep, node_class=node_class, identifier=identifier)\n",
    "\n",
    "    # Library has a bug that won't show trees correctly unless stdout=False is added.\n",
    "    def display(self):\n",
    "        print(self.show(stdout=False))\n",
    "\n",
    "    #  -- NEW NODE GENERATION\n",
    "\n",
    "    # Let's override original create_node method in order to add new constraints such as child node number and true/false branchs.\n",
    "    def create_node(self, tag=None, identifier=None, parent=None, data=None,branch=None):\n",
    "        \"\"\"\n",
    "        Create a child node for the given @parent node. If ``identifier`` is absent,\n",
    "        a UUID will be generated automatically.\n",
    "        \"\"\"\n",
    "        \n",
    "        new_node = super(SequenceTrunk, self).create_node(tag=tag, parent=parent, data=data)\n",
    "        siblings = super(SequenceTrunk,self).siblings(new_node.identifier)\n",
    "        \n",
    "        if len(super(SequenceTrunk,self).siblings(new_node.identifier))>=2:\n",
    "           raise ValueError(\"Parent node already has maximum number of children\")\n",
    "\n",
    "        if branch in [x.data[\"branch\"] for x in siblings]:\n",
    "           raise ValueError(f\"Parent node already has a {branch} branch\")\n",
    "        \n",
    "        return new_node\n",
    "    \n",
    "    def create_node_event(self,data,parent=None,branch=None,entropy=\"\",size=0,ig=\"\",index=\"\"):\n",
    "        branch_f = \"\" if (branch is None) else str(branch)+\" \"\n",
    "        tag =  f\"\\x1b[32m⬤ {branch_f} ({str(data[1])},{format_timedelta(data[0])})\\x1b[0m - [e={float(entropy):4.2} ig={float(ig):4.2}] [n={size}] {index}\"\n",
    "        data = {\"branch\":branch, \"dl\":(data[0],data[1]),\"entropy\":entropy,\"ig\":ig,\"index\":index}\n",
    "\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    def create_node_value(self,label_value,parent=None,branch=None,entropy=\"\",size=0,ig=\"\",index=\"\"):\n",
    "        branch_f = \"\" if (branch is None) else branch+\" \"\n",
    "        tag =  f\"\\x1b[31m■ {branch_f} ({label_value[0]}, {label_value[1]}) \\x1b[0m- [e={float(entropy):2.2} ig={ig:4.2}] [n={size}] {index}\"\n",
    "        data = {\"branch\":branch,\"value\":label_value,\"entropy\":entropy,\"index\":index}\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    def create_node_class(self,classification,parent=None,branch=None,entropy=\"\",size=0,index=\"\"):\n",
    "        branch_f = \"\" if (branch is None) else str(branch)+\" \"\n",
    "\n",
    "        tag =  f\"\\x1b[33m◆ {branch_f} {classification} \\x1b[0m- [e={float(entropy):2.2}] \\x1b[33m[n={size}]\\x1b[0m - {index}\"\n",
    "\n",
    "        # If the classsification had \"max length reached\", remove the tag from data\n",
    "        if isinstance(classification, str):\n",
    "            classification = int(classification[0])\n",
    "\n",
    "        data = {\"branch\":branch, \"class\":classification,\"entropy\":entropy,\"index\":index}\n",
    "\n",
    "\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    #  -- EVENT TESTING\n",
    "\n",
    "    # Given a pair of duration d and label l, computes its information gain on the dataset if we were to split it according to the sequence tree rules.\n",
    "    def __compute_IG_event(self,dl_pair,dataset_X,dataset_Y,dataset_ST,verbose=False):\n",
    "        #if verbose:\n",
    "        #   print(f\"Computing IG for {dl_pair}\")\n",
    "\n",
    "        entropy_0 = compute_entropy(dataset_Y)\n",
    "\n",
    "        i_T, i_F = test_event(dataset_X,dl_pair,dataset_ST)\n",
    "        \n",
    "        #2. Compute final entropy. first let's generate our new datasets...\n",
    "        dataset_Yt=[ dataset_Y[i] for i in i_T]\n",
    "        dataset_Yf=[ dataset_Y[i] for i in i_F]\n",
    "                \n",
    "        entropy_f = (len(i_T)/len(dataset_X))*compute_entropy(dataset_Yt) + (len(i_F)/len(dataset_X))*compute_entropy(dataset_Yf)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"information gain is {entropy_0-entropy_f} {entropy_0}-> {[ dataset_Y[i] for i in i_T],[ dataset_Y[i] for i in i_F]} {entropy_f}\")\n",
    "            \n",
    "        return(entropy_0-entropy_f,i_T,i_F)\n",
    "\n",
    "    # Given all possible pairs of d,l finds the one with the highest information gain (aka the one I should actually split on)\n",
    "    def __maximize_IG_event(self,dataset_X,dataset_Y, dataset_ST, indexes=None,verbose=False,howmany=30,random_sampling=False):\n",
    "        if indexes is None:\n",
    "            indexes = range(0,len(dataset_X))\n",
    "\n",
    "        \n",
    "        dl_pairs = create_pairs([dataset_X[i] for i in indexes],[dataset_ST[i] for i in indexes],howmany,random_sampling)\n",
    "\n",
    "\n",
    "        igs_list = [(x,self.__compute_IG_event(x,dataset_X,dataset_Y,dataset_ST,verbose)) for x in dl_pairs]\n",
    "        # ogni entry di igs_list è ( (d,l) , (ig,i_T,i_F)   )\n",
    "\n",
    "        max_ig=-1\n",
    "        max_dl=None\n",
    "\n",
    "        for ((d,l),(ig,i_T,i_F)) in igs_list:\n",
    "            if ig > max_ig:\n",
    "                max_ig=ig\n",
    "                max_dl = ((d,l),(ig,i_T,i_F))\n",
    "\n",
    "        \n",
    "        if len(max_dl[1][1])==0 or len(max_dl[1][2])==0:\n",
    "            if verbose:\n",
    "                print(\"Split failed, couldn't find a d,l that separates values :(\")\n",
    "            return None, 0\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Max IG is in couple d=\",format_timedelta(max_dl[0][0]),\", l=\",max_dl[0][1],\", IG=\",max_dl[1])\n",
    "\n",
    "        max_dl = (max_dl[0],max_dl[1][0])\n",
    "        return max_dl\n",
    "\n",
    "    # Given a d,l couple, split the dataset in two and update starting times and dataset values.\n",
    "    def __perform_event_test(self,max_dl,indexes,dataset_X,dataset_ST,dataset_V,verbose=False):\n",
    "        # divide dataset in t and f...\n",
    "        i_T = []\n",
    "        i_F = []\n",
    "\n",
    "        d,l = max_dl\n",
    "        old_dataset_ST=dataset_ST\n",
    "        \n",
    "        for i in range(0,len(dataset_ST)):\n",
    "            entry = dataset_X[i]\n",
    "\n",
    "            found=False\n",
    "\n",
    "            for item in entry:\n",
    "                #starting from the starting time, see if it exists an item with timestamp < d and label == l\n",
    "                \n",
    "                if(found is False and item[0]>= old_dataset_ST[i] and item[0]<=(old_dataset_ST[i]+d) and item[1]==l ): # If i'm over starting time\n",
    "                    found=True\n",
    "                    dataset_ST[i] = item[0]\n",
    "                    dataset_V[i] = item[2]\n",
    "\n",
    "            if(found):\n",
    "                i_T.append(i)\n",
    "            else:\n",
    "                i_F.append(i)\n",
    "                \n",
    "        return i_T,i_F,dataset_ST,dataset_V\n",
    "\n",
    "    #  -- VALUE TESTING\n",
    "\n",
    "    # Given a dataset, test out all possible values and see which one would lead to the best split. If we have called this function, it means we are in a true branch and all values in dataset_V are already of a single label.\n",
    "    def __maximize_IG_value(self,dataset_V,dataset_Y):\n",
    "        values = set([v for v in dataset_V])\n",
    "        values_ig = []\n",
    "\n",
    "        for v in values:   \n",
    "            entropy_0 = compute_entropy(dataset_Y)\n",
    "            i_T=[]\n",
    "            i_F=[]\n",
    "            for i in range(0,len(dataset_V)):\n",
    "                if dataset_V[i] <= v:\n",
    "                    i_T.append(i)\n",
    "                else:\n",
    "                    i_F.append(i)\n",
    "            dataset_Yt=[ dataset_Y[i] for i in i_T]\n",
    "            dataset_Yf=[ dataset_Y[i] for i in i_F]\n",
    "            entropy_f = (len(i_T)/len(dataset_Y))*compute_entropy(dataset_Yt) + (len(i_F)/len(dataset_Y))*compute_entropy(dataset_Yf)\n",
    "            ig = entropy_0-entropy_f\n",
    "            values_ig.append((v,ig))\n",
    "\n",
    "        return max(values_ig, key=lambda x: x[1])\n",
    "\n",
    "    # Given a d,l couple, split the dataset in two and update dataset values.\n",
    "    def __perform_value_test(self,value,dataset_V):\n",
    "        i_T=[]\n",
    "        i_F=[]\n",
    "        for i in range(0,len(dataset_V)):\n",
    "            if dataset_V[i] <= value:\n",
    "                i_T.append(i)\n",
    "            else:\n",
    "                i_F.append(i)\n",
    "        return i_T,i_F\n",
    "\n",
    "    #  -- FIT ALGORITHM\n",
    "        \n",
    "    def fit(self,dataset_X,dataset_Y,dataset_V,dataset_ST,max_depth:int,parent=None,branch=None,depth=0,indexes=[],verbose=False):\n",
    "        \"\"\"\n",
    "        Implements the fit algorithm as described in the exercise text.\n",
    "\n",
    "        :param list dataset_X: Dataset entries, where each entry is a list of items (time,label,value)\n",
    "        :param list dataset_Y: classes of the dataset, each entry is the class of the dataset entry with the same index\n",
    "        :param list dataset_V: it's a int value if there has been a previous (d,l) test, otherwise it's None\n",
    "        :param list dataset_ST: current starting time (aka, how much of the list I've already read)\n",
    "        :param SequenceTree tree: the SequenceTree tree we're building.\n",
    "        :param int max_depth: how deep can the SequenceTree be before we stop creating new nodes and approximate the result.\n",
    "        :param parent: identifier of the parent node.\n",
    "        :param branch: whether the true node is on the true or false branch.\n",
    "        :param depth: depth of the current node.\n",
    "        :param indexes: original indexes of the entries currently being processed.\n",
    "        :param verbose: prints more info.\n",
    "        \"\"\"\n",
    "        #if ((parent is None) and (event is None) ):\n",
    "        #    raise ValueError('The root of the Sequence Trunk must specify an event.')\n",
    "        \n",
    "        if(parent is None and verbose):\n",
    "            print(\"-- Fit\")\n",
    "        \n",
    "        # BASE CASES:\n",
    "        \n",
    "        # 1. If I have 1 node only or all the classes are the same, or this is the false child of the parent, make a leaf\n",
    "        if  (parent and \"dl\" in parent.data.keys() and branch==\"f\") or (len(dataset_X)==1) or (all(element == dataset_Y[0] for element in dataset_Y)) :\n",
    "            if verbose:\n",
    "                if (parent and \"dl\" in parent.data.keys() and branch==\"f\"):\n",
    "                    print(\"False branch after dl, creating class node..\")\n",
    "                else:\n",
    "                    print(f\"{depth,branch} All items are the same class!\")\n",
    "            self.create_node_class(classification=dataset_Y[0],parent=parent,branch=branch,entropy=compute_entropy(dataset_Y),size=len(dataset_Y),index=indexes)\n",
    "            return         \n",
    "        \n",
    "        # 2. If I've reached the maximum number of tests allowed, create a leaf with the extimation of the class.\n",
    "        elif depth > max_depth:\n",
    "            if (verbose):\n",
    "                print(\"Reached maximum depth!\")\n",
    "            y_1 = sum(1 for c in dataset_Y if c == 1)\n",
    "            y_0 = sum(1 for c in dataset_Y if c == 0)\n",
    "            estimated_class = 1 if y_1>y_0 else 0  \n",
    "            estimated_class = str(estimated_class)+\" MAX DEPTH REACHED\"\n",
    "\n",
    "            self.create_node_class(estimated_class,parent,branch,compute_entropy(dataset_Y),len(dataset_Y),indexes)\n",
    "            return\n",
    "\n",
    "\n",
    "        # INDUCTIVE CASE\n",
    "\n",
    "        # If root, compute test event. Otherwise, do value test.\n",
    "        if (parent is None):\n",
    "            \n",
    "            max_dl, max_dl_ig = self.__maximize_IG_event(dataset_X,dataset_Y,dataset_ST,range(len(dataset_X)),False,howmany=30,random_sampling=False)\n",
    "            node = self.create_node_event(max_dl,parent,branch,compute_entropy(dataset_Y),len(dataset_Y),max_dl_ig)\n",
    "            \n",
    "            i_T, i_F, dataset_ST, dataset_V=self.__perform_event_test(max_dl,indexes,dataset_X,dataset_ST,dataset_V)\n",
    "\n",
    "            self.fit([dataset_X[i] for i in i_T],[dataset_Y[i] for i in i_T],[dataset_V[i] for i in i_T],[dataset_ST[i] for i in i_T],max_depth,node,\"t\",depth+1,[indexes[i] for i in i_T])\n",
    "            self.fit([dataset_X[i] for i in i_F],[dataset_Y[i] for i in i_F],[dataset_V[i] for i in i_F],[dataset_ST[i] for i in i_F],max_depth,node,\"f\",depth+1,[indexes[i] for i in i_F])\n",
    "        else:\n",
    "            max_value, max_value_ig=self.__maximize_IG_value(dataset_V,dataset_Y)\n",
    "            label = parent.data[\"dl\"][1] if \"dl\" in parent.data.keys() else parent.data[\"value\"][0]\n",
    "\n",
    "            # If the separation didn't actually separate a result, just make a class node..\n",
    "            if max_value_ig == 0.0:\n",
    "                classification = -1 if sum(dataset_Y) <= 0.5 else 1\n",
    "                self.create_node_class(classification=classification,parent=parent,branch=branch,entropy=compute_entropy(dataset_Y),size=len(dataset_Y),index=indexes)\n",
    "                return\n",
    "\n",
    "\n",
    "            node = self.create_node_value((label,max_value),parent,branch,compute_entropy(dataset_Y),len(dataset_Y),max_value_ig)\n",
    "            i_T, i_F=self.__perform_value_test(max_value,dataset_V)\n",
    "\n",
    "            self.fit([dataset_X[i] for i in i_T],[dataset_Y[i] for i in i_T],[dataset_V[i] for i in i_T],[dataset_ST[i] for i in i_T],max_depth,node,\"t\",depth+1,[indexes[i] for i in i_T])\n",
    "            self.fit([dataset_X[i] for i in i_F],[dataset_Y[i] for i in i_F],[dataset_V[i] for i in i_F],[dataset_ST[i] for i in i_F],max_depth,node,\"f\",depth+1,[indexes[i] for i in i_F])\n",
    "\n",
    " \n",
    "    #  -- PREDICT ALGORITHM\n",
    "\n",
    "    def __predict_r(self,entry_X,entry_ST,entry_V,node:Node,verbose=False):\n",
    "\n",
    "        if verbose:\n",
    "            print(node)\n",
    "            \n",
    "        # BASE CASE\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            if verbose:\n",
    "                print(\"end\")\n",
    "            return node.data[\"class\"]\n",
    "\n",
    "\n",
    "        # INDUCTIVE CASE    \n",
    "\n",
    "        children = [self.get_node(x) for x in node.successors(self.identifier)]\n",
    "\n",
    "        if \"dl\" in node.data.keys():\n",
    "            if verbose:\n",
    "                print(\"dl test\")\n",
    "            i_T,i_F,entry_ST,entry_V = self.__perform_event_test(node.data[\"dl\"],None,entry_X,entry_ST,entry_V)\n",
    "\n",
    "            branch = \"t\" if i_T else \"f\"\n",
    "            next_node = list(filter(lambda x : x.data[\"branch\"]==branch,children))[0]\n",
    "\n",
    "            return self.__predict_r(entry_X,entry_ST,entry_V,next_node)\n",
    "\n",
    "        elif \"value\" in node.data.keys():\n",
    "            if verbose:\n",
    "                print(\"value test\")\n",
    "            i_T,i_F = self.__perform_value_test(node.data[\"value\"][1],entry_V)\n",
    "            branch = \"t\" if i_T else \"f\"\n",
    "            next_node = list(filter(lambda x : x.data[\"branch\"]==branch,children))[0]\n",
    "\n",
    "            return self.__predict_r(entry_X,entry_ST,entry_V,next_node)\n",
    "\n",
    "    # Given a list of new entries, computes the prediction and returns it. It also prints the confusion matrix!\n",
    "    def predict(self,entry_X,entry_ST,entry_V,entry_Y,verbose=False):\n",
    "        if verbose:\n",
    "            print(\"-- Predict\")\n",
    "        results=[]\n",
    "        root = self.get_node(self.root)\n",
    "\n",
    "\n",
    "        if isinstance(dataset_V,list) and len(dataset_V)==1:\n",
    "            entry_X = [entry_X]\n",
    "            entry_Y = [entry_Y]\n",
    "            entry_ST = [entry_ST]\n",
    "            entry_V = [entry_V]\n",
    "            results.append(self.__predict_r(self.entry_X,entry_ST,entry_V,root),verbose)\n",
    "        else:\n",
    "            for i in range(0,len(entry_ST)):\n",
    "                results.append(self.__predict_r([entry_X[i]],[entry_ST[i]],[entry_V[i]],root,verbose))\n",
    "        \n",
    "        if verbose:\n",
    "            tp = sum(1 for x, y in zip(results, entry_Y) if (x == 1 and y==1))\n",
    "            tn = sum(1 for x, y in zip(results, entry_Y) if (x == -1 and y==-1))\n",
    "            fp = sum(1 for x, y in zip(results, entry_Y) if (x == 1 and y==-1))\n",
    "            fn = sum(1 for x, y in zip(results, entry_Y) if (x == -1 and y==1))\n",
    "\n",
    "            print(f\"\\tP\\tN\\nP\\t{tp}\\t{fn}\\nN\\t{fp}\\t{tn}\")\n",
    "            print(f\"Items: {tp+tn+fp+fn}\")\n",
    "            print(f\"Accuracy: {float((tp+tn)/(tp+tn+fp+fn)):4.3}\")\n",
    "\n",
    "        return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DS loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSkipped 46 items for formatting issues in data file. 70 loaded.\n",
      "-- DS builder\n",
      "\t2 entries unsuitable for selected windows.\n",
      "\tFinal dataset size: 68. Classes: 31|37, entropy  0.0\n",
      "(datetime.timedelta(days=558, seconds=4140), '58')\n",
      "\u001b[32m⬤  (48,2d 17h 1m 1s)\u001b[0m - [e= 1.0 ig= 0.2] [n=67] \n",
      "├── \u001b[31m■ t  (48, 109) \u001b[0m- [e=0.45 ig=0.059] [n=21] \n",
      "│   ├── \u001b[33m◆ f  1 MAX DEPTH REACHED \u001b[0m- [e=0.59] \u001b[33m[n=14]\u001b[0m - [0, 5, 6, 9, 19, 20, 25, 29, 39, 51, 53, 54, 63, 65]\n",
      "│   └── \u001b[33m◆ t  -1 \u001b[0m- [e=0.0] \u001b[33m[n=7]\u001b[0m - [1, 26, 27, 28, 30, 40, 52]\n",
      "└── \u001b[33m◆ f  1 \u001b[0m- [e=0.95] \u001b[33m[n=46]\u001b[0m - [2, 3, 4, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reload ds\n",
    "dataset_X,dataset_Y, dataset_ST,dataset_V = reload_ds()\n",
    "dataset_Y = [(1 if x==1 else -1) for x in dataset_Y]   \n",
    "\n",
    "#--Fit\n",
    "event=(dataset[0][0][0] - dataset[1][0][0],dataset[0][0][1])\n",
    "print(event)\n",
    "\n",
    "tree = SequenceTrunk()\n",
    "tree.fit(dataset_X,dataset_Y,dataset_V,dataset_ST,max_depth=1,indexes=range(0,len(dataset_X)))\n",
    "if len(tree.all_nodes()) != 0:\n",
    "    print(tree)\n",
    "\n",
    "#--Predict\n",
    "    # Choose which entries to test\n",
    "rangee=len(dataset_V)\n",
    "entry_X,entry_Y, entry_ST,entry_V = dataset_X[0:rangee],dataset_Y[0:rangee], dataset_ST[0:rangee],dataset_V[0:rangee]\n",
    "    # Test'em!\n",
    "predictions = tree.predict(entry_X,entry_ST,entry_V,entry_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up datasets for Boosting task\n",
    "def reload_boosting():\n",
    "    dataset_X,dataset_Y, dataset_ST,dataset_V = reload_ds()\n",
    "    dataset_Y = [(1 if x==1 else -1) for x in dataset_Y] \n",
    "\n",
    "    return  dataset_X,dataset_Y, dataset_ST,dataset_V\n",
    "#print_dataset_state(dataset_X,dataset_Y,dataset_ST,dataset_V,dataset_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def compute_treeerr(tree,dataset_Y):\n",
    "    leaves = tree.leaves()\n",
    "    tree_err = 0\n",
    "    for leaf in leaves:\n",
    "        err = 0\n",
    "        classification_predict = leaf.data[\"class\"]\n",
    "        for index in leaf.data[\"index\"]:\n",
    "            if dataset_Y[index] != classification_predict:\n",
    "                err+=1\n",
    "        tree_err+=err\n",
    "    tree_err = (1/(len(dataset_Y)))*tree_err\n",
    "    return tree_err\n",
    "\n",
    "def flip_tree(tree):\n",
    "    for node in tree.leaves():\n",
    "        node.data[\"class\"] = 1 if node.data[\"class\"]==-1 else -1\n",
    "        node.tag  = node.tag.replace(\" -1 \",\" AAA \")\n",
    "        node.tag  = node.tag.replace(\" 1 \",\" BBB \")\n",
    "        node.tag  = node.tag.replace(\" AAA \",\" 1 \")\n",
    "        node.tag  = node.tag.replace(\" BBB \",\" -1 \")\n",
    "    return\n",
    "\n",
    "def print_weights_status(training_W,training_alpha,training_phi,dataset_Y,alpha,err):\n",
    "    #Stats\n",
    "    print(f\"--- iteration:{len(training_W)-1}\\n - α:{alpha:4.3}\\n - err:{err:4.3}\")\n",
    "\n",
    "    # Header\n",
    "    print(\"i\\t\",end=\"\")\n",
    "    for i in range(0,len(training_W)):\n",
    "        print(f\"w{i}\\t\\t\",end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    #range_to_print = list(range(0,3))+list(range(len(dataset_Y)-3,len(dataset_Y)))\n",
    "    range_to_print = range(0,len(dataset_Y))\n",
    "    # Weights\n",
    "    for item in range_to_print: #each row in the DS\n",
    "        print(f\"{item}\\t\",end=\"\")\n",
    "        for step in range(0,len(training_W)): # each weight\n",
    "            print(f\"{training_W[step][item]:4.2}\",end=\"\")\n",
    "            if step!=0:\n",
    "                andamento = f\"{\"\\x1b[31m↑\\033[0;37m\" if training_W[step-1][item]<training_W[step][item] else \"\\033[0;32m↓\\033[0;37m\"}\"\n",
    "                if training_W[step-1][item]==training_W[step][item]:\n",
    "                    andamento=\"!\"\n",
    "                print(andamento,end=\"\")\n",
    "            print(\"\\t\\t\",end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_trunk(dataset_X,dataset_ST,dataset_Y,dataset_V,weights):\n",
    "\n",
    "    # Generate sampled dataset\n",
    "    sampled_X = []\n",
    "    sampled_ST = []\n",
    "    sampled_V = []\n",
    "    sampled_Y = []\n",
    "    sampled_indexes = []\n",
    "    for _ in range(0,100):\n",
    "        # 1. Extract one item. THE LIKELIHOOD MUST BE ACCORDING TO WEIGHTS. \n",
    "        sample = random.choices(range(0,len(dataset_X)), weights=weights, k=1)[0]\n",
    "        sampled_X.append(dataset_X[sample])\n",
    "        sampled_ST.append(dataset_ST[sample])\n",
    "        sampled_V.append(dataset_V[sample])\n",
    "        sampled_Y.append(dataset_Y[sample])\n",
    "        sampled_indexes.append(sample)\n",
    "\n",
    "    # Find tree\n",
    "    tree = SequenceTrunk()\n",
    "    tree.fit(sampled_X,sampled_Y,sampled_V,sampled_ST,1,indexes=sampled_indexes)\n",
    "\n",
    "\n",
    "    tree_err = compute_treeerr(tree,sampled_Y)\n",
    "    flipped = False\n",
    "    if tree_err > 0.5:\n",
    "        flipped = True\n",
    "        flip_tree(tree)\n",
    "        tree_err = compute_treeerr(tree,dataset_Y)\n",
    "    return tree, tree_err, flipped\n",
    "\n",
    "tree, tree_err, flipped = find_best_trunk(dataset_X,dataset_ST,dataset_Y,dataset_V,[1]*len(dataset_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DS loader\n",
      "\tSkipped 46 items for formatting issues in data file. 70 loaded.\n",
      "-- DS builder\n",
      "\t2 entries unsuitable for selected windows.\n",
      "\tFinal dataset size: 68. Classes: 31|37, entropy  0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SequenceTrunk' object has no attribute '__perform_event_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m training_W\u001b[38;5;241m.\u001b[39mappend(training_W1)\n\u001b[0;32m     77\u001b[0m d,l \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mget_node(tree\u001b[38;5;241m.\u001b[39mroot)\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 78\u001b[0m _,_,new_ST,new_V \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__perform_event_test\u001b[49m((d,l),\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(training_X[iteration])),training_X[iteration],training_ST[iteration],training_V[iteration])\n\u001b[0;32m     79\u001b[0m training_X\u001b[38;5;241m.\u001b[39mappend(training_X[iteration])\n\u001b[0;32m     80\u001b[0m training_ST\u001b[38;5;241m.\u001b[39mappend(new_ST)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequenceTrunk' object has no attribute '__perform_event_test'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed()\n",
    "\n",
    "dataset_X,dataset_Y, dataset_ST,dataset_V= reload_boosting()\n",
    "\n",
    "training_W = [[1/len(dataset_Y)]*len(dataset_Y)]\n",
    "training_phi = []\n",
    "training_X = [dataset_X]\n",
    "training_ST = [dataset_ST]\n",
    "training_V = [dataset_V]\n",
    "training_alpha = []\n",
    "training_errs = []\n",
    "\n",
    "\n",
    "for iteration in range(0,50):\n",
    "\n",
    "    #Find best trunk \n",
    "\n",
    "    tree, _, _ = find_best_trunk(training_X[iteration],training_ST[iteration],dataset_Y,training_V[iteration],training_W[iteration])\n",
    "    training_phi.append(tree)\n",
    "\n",
    "    #predictions = tree.predict(training_X[iteration],training_ST[iteration],training_V[iteration],dataset_Y)\n",
    "\n",
    "    #i_correct=[]\n",
    "    #i_mistaken=[]\n",
    "    #for i in range(0,len(training_X[iteration])):\n",
    "    #    if predictions[i]==dataset_Y[i]:\n",
    "    #        i_correct.append(i)\n",
    "    #    else:\n",
    "    #        i_mistaken.append(i)#\n",
    "    #err = len(i_mistaken)/len(training_X[iteration])\n",
    "\n",
    "    i_correct = []\n",
    "    i_mistaken = []\n",
    "    errcount=0\n",
    "    if iteration > 0:\n",
    "        for item_i in range(0,len(dataset_Y)):\n",
    "            final_response = 0\n",
    "            for iteration_i in range(0,iteration):\n",
    "                alpha = training_alpha[iteration_i]\n",
    "                prediction = alpha*training_phi[iteration_i].predict([training_X[iteration_i][item_i]],[training_ST[iteration_i][item_i]],[training_V[iteration_i][item_i]],[dataset_Y[i]])[0]\n",
    "                final_response+=prediction\n",
    "            final_response = 1 if final_response > 0 else -1\n",
    "            if final_response != dataset_Y[item_i]:\n",
    "                errcount+=1\n",
    "                i_mistaken.append(item_i)\n",
    "            else:\n",
    "                i_correct.append(item_i)\n",
    "        err = float(errcount)/len(dataset_Y)\n",
    "    else:\n",
    "        predictions = training_phi[iteration].predict(training_X[iteration],training_ST[iteration],training_V[iteration],dataset_Y)\n",
    "        \n",
    "        for i in range(0,len(predictions)):\n",
    "            if predictions[i]==dataset_Y[i]:\n",
    "                i_correct.append(i)\n",
    "            else:\n",
    "                i_mistaken.append(i)\n",
    "                errcount+=1\n",
    "        err = (float(errcount)/len(dataset_Y))\n",
    "    training_errs.append(err)\n",
    "    alpha = 0.5*math.log2((1-err)/(err))\n",
    "\n",
    "\n",
    "    # Compute new weights\n",
    "    training_W1=[None]*len(dataset_Y)\n",
    "    for index in i_correct:\n",
    "        training_W1[index]=training_W[iteration][index]*(math.sqrt(err/(1-err)))\n",
    "    for index in i_mistaken:\n",
    "        training_W1[index]=training_W[iteration][index]*(math.sqrt((1-err)/(err)))\n",
    "    z = sum(training_W1)\n",
    "    training_W1 = [w/z for w in training_W1]\n",
    "\n",
    "\n",
    "    # Update sets TODO\n",
    "    training_W.append(training_W1)\n",
    "\n",
    "    d,l = tree.get_node(tree.root).data[\"dl\"]\n",
    "    _,_,new_ST,new_V = tree.__perform_event_test((d,l),list(0,len(training_X[iteration])),training_X[iteration],training_ST[iteration],training_V[iteration])\n",
    "    training_X.append(training_X[iteration])\n",
    "    training_ST.append(new_ST)\n",
    "    training_V.append(new_V)\n",
    "    training_alpha.append(alpha)\n",
    "\n",
    "    # Update err\n",
    "    #for i in range(0,len(training_phi)):\n",
    "    #    test_X = training_X[i]\n",
    "    #    test_ST = training_ST[i]\n",
    "    #    test_V = training_V[i]\n",
    "    #    weak_prediction = training_phi[i].predict(test_X,test_ST,test_V,dataset_Y)\n",
    "    #print(len(weak_prediction),len(training_alpha))\n",
    "    \n",
    "    #errcount=0\n",
    "    #errcount=0\n",
    "    #for item_i in range(0,len(dataset_Y)):\n",
    "    #    final_response = 0\n",
    "    #    for iteration_i in range(0,iteration+1):\n",
    "    #        alpha = training_alpha[iteration_i]\n",
    "    #        #print(training_X[iteration_i][item_i])\n",
    "    #        prediction = alpha*training_phi[iteration_i].predict([training_X[iteration_i][item_i]],[training_ST[iteration_i][item_i]],[training_V[iteration_i][item_i]],[dataset_Y[i]])[0]\n",
    "    #        final_response+=prediction\n",
    "    #    final_response = 1 if final_response > 0 else -1\n",
    "    #    if final_response != dataset_Y[item_i]:\n",
    "    #        errcount+=1\n",
    "    #verr = float(errcount)/len(dataset_Y)\n",
    "    #training_errs.append(err)\n",
    "\n",
    "    print(f\"Iteration {iteration} - alpha {alpha:4.2} - err {err}\")\n",
    "\n",
    "print_weights_status(training_W,training_alpha,training_phi,dataset_Y,alpha,err)\n",
    "print_alphas(training_alpha,training_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6119402985074627, 0.3880597014925373, 0.3880597014925373, 0.417910447761194, 0.417910447761194, 0.5373134328358209, 0.5373134328358209, 0.5223880597014925, 0.5223880597014925, 0.5373134328358209, 0.5522388059701493, 0.47761194029850745, 0.4925373134328358, 0.4925373134328358, 0.4925373134328358, 0.5373134328358209, 0.47761194029850745, 0.5074626865671642, 0.4925373134328358, 0.5373134328358209, 0.47761194029850745, 0.4925373134328358, 0.47761194029850745, 0.47761194029850745, 0.4626865671641791, 0.5970149253731343, 0.417910447761194, 0.5373134328358209, 0.44776119402985076, 0.5522388059701493, 0.4925373134328358, 0.4925373134328358, 0.4925373134328358, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.5223880597014925, 0.47761194029850745, 0.5074626865671642, 0.5074626865671642, 0.5074626865671642, 0.47761194029850745, 0.4925373134328358]\n",
      "[-0.32855614323849575, 0.32855614323849575, 0.32855614323849575, 0.2390236484023222, 0.2390236484023222, -0.10786434552771854, -0.10786434552771854, -0.06464150847248308, -0.06464150847248308, -0.10786434552771854, -0.1512813850102158, 0.06464150847248323, 0.02153436094594312, 0.02153436094594312, 0.02153436094594312, -0.10786434552771854, 0.06464150847248323, -0.021534360945943073, 0.02153436094594312, -0.10786434552771854, 0.06464150847248323, 0.02153436094594312, 0.06464150847248323, 0.06464150847248323, 0.10786434552771863, -0.28352029636194676, 0.2390236484023222, -0.10786434552771854, 0.15128138501021565, -0.1512813850102158, 0.02153436094594312, 0.02153436094594312, 0.02153436094594312, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, -0.06464150847248308, 0.06464150847248323, -0.021534360945943073, -0.021534360945943073, -0.021534360945943073, 0.06464150847248323, 0.02153436094594312]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def print_alphas(training_alpha,training_errs):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(3,3))  # Width, Height in inches\n",
    "    # Adding labels\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('alpha/err')\n",
    "    plt.plot(training_errs,label=\"error\")\n",
    "    plt.plot(training_alpha,label=\"alpha\")\n",
    "    _ = plt.legend(loc='lower right')\n",
    "    plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "    # Displaying the plot\n",
    "    plt.show()\n",
    "print(training_errs)\n",
    "print(training_alpha)\n",
    "print_alphas(training_alpha,training_errs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 4 - Boosting classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some helper functions from previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import os\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# Takes a timedelta and prints it in a human-readable format.\n",
    "def format_timedelta(td: timedelta) -> str:\n",
    "    days = td.days\n",
    "    years, days = divmod(days, 365)\n",
    "    months, days = divmod(days, 30)\n",
    "    hours, remainder = divmod(td.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    formatted_str = \"\"\n",
    "    if years:\n",
    "        formatted_str += f\"{years}y \"\n",
    "    if months:\n",
    "        formatted_str += f\"{months}mo \"\n",
    "    if days:\n",
    "        formatted_str += f\"{days}d \"\n",
    "    if hours:\n",
    "        formatted_str += f\"{hours}h \"\n",
    "    if minutes:\n",
    "        formatted_str += f\"{minutes}m \"\n",
    "    if seconds:\n",
    "        formatted_str += f\"{seconds}s \"\n",
    "    \n",
    "\n",
    "    \n",
    "    return formatted_str[:-1] if formatted_str else \"0s\"\n",
    "  \n",
    "# Given a set with binary classes, computes entropy\n",
    "def compute_entropy(dataset_Y,second_class=-1):\n",
    "    ones = len(list(filter(lambda classification : classification == 1,dataset_Y)))\n",
    "    zeros = len(list(filter(lambda classification : classification == second_class,dataset_Y)))\n",
    "\n",
    "    if(ones == 0 or zeros==0):\n",
    "        return 0\n",
    "    \n",
    "    entropy = ones/len(dataset_Y)*math.log2(1/(ones/len(dataset_Y))) + zeros/len(dataset_Y)*math.log2(1/(zeros/len(dataset_Y)))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "# returns a list of tuples (i,x) where i is the index of the patient in the dataset and x is a timedelta of per quanto tempo abbiamo rilevazioni\n",
    "def find_durations(dataset):\n",
    "    lengths = []\n",
    "    for entry in dataset:\n",
    "        min_t = datetime.max\n",
    "        max_t = datetime.min\n",
    "        for item in entry:\n",
    "            if item[0] < min_t:\n",
    "                min_t = item[0]\n",
    "            elif item[0] > max_t:\n",
    "                max_t = item[0]\n",
    "        lengths.append(max_t-min_t)\n",
    "    return [(i, x) for i, x in enumerate(lengths)]\n",
    "\n",
    "# Find al possible d,l couples that I could split the tree on. Note: Ds are randomly/evenly selected bc otherwise I'd end up with ~36000 pairs...\n",
    "def create_pairs(dataset_X:list,dataset_ST:list,howmany_d =30,random_sampling=False):\n",
    "\n",
    "    #1. Create all labels available from current\n",
    "    labels = set()\n",
    "    for i in range(0,len(dataset_X)):\n",
    "        for item in dataset_X[i]:\n",
    "            if (item[0] > dataset_ST[i]):# Only consider label if it's not been superato\n",
    "                labels.add(item[1])\n",
    "\n",
    "\n",
    "    #2. Find all d\n",
    "    durations = set()\n",
    "    if random_sampling:\n",
    "        durations = set()\n",
    "        for i in range(0,len(dataset_X)):\n",
    "            for item in dataset_X[i]:\n",
    "                if (item[0] > dataset_ST[i]): # Only consider timestamp if it's not been superato\n",
    "                    durations.add(item[0]-dataset_ST[i])\n",
    "        if len(durations)>howmany_d:\n",
    "            durations = random.sample(sorted(durations),howmany_d) # Is this ok?\n",
    "        else:\n",
    "            durations = sorted(durations)\n",
    "    else:\n",
    "        durations = set()\n",
    "        for i in range(0,len(dataset_X)):\n",
    "            for item in dataset_X[i]:\n",
    "                durations.add(item[0]-dataset_ST[i])\n",
    "        delta = max(durations)/(howmany_d+1)\n",
    "        durations = set()\n",
    "        for i in range(1,howmany_d+1):\n",
    "            durations.add(delta*i)\n",
    "\n",
    "    return sorted(list(itertools.product(durations,labels)))\n",
    "\n",
    "# Given a d,l couple, split the dataset and return indexes of true and false entries.\n",
    "def test_event(dataset_X,dl_pair,dataset_ST):\n",
    "    i_T = [] # indexes of entries that have label==l within d time\n",
    "    i_F = [] # indexes of entries that have DON'T HAVE label==l within d time\n",
    "    d,l = dl_pair\n",
    "\n",
    "\n",
    "    #1. Separate entries that satisfy event test from those who don't\n",
    "    for i in range(0,len(dataset_X)):\n",
    "        entry = dataset_X[i]\n",
    "        found=False\n",
    "\n",
    "        for item in entry:\n",
    "            #print(item)\n",
    "            if(found is False and item[0]>=dataset_ST[i] and item[0]<=(dataset_ST[i]+d) and item[1]==l ):\n",
    "                found=True\n",
    "\n",
    "        if(found):\n",
    "            i_T.append(i)\n",
    "        else:\n",
    "            i_F.append(i)\n",
    "    return i_T,i_F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and parsing DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_diabetes_dataset(verbose=False)-> list: \n",
    "    folder_path=\"datasets\\\\diabetes\"\n",
    "    dataset = []\n",
    "    errcount=0\n",
    "    print(f\"-- DS loader\")\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path)and filename.startswith('data'):\n",
    "            entry=[]\n",
    "\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.readlines()\n",
    "                for line in content:\n",
    "                    item = tuple((line[0:-1] if line.endswith('\\n') else tuple(line)).split(\"\\t\"))\n",
    "\n",
    "                    # If the item is valid, append it to the entry\n",
    "                    try:\n",
    "                        item_f = datetime.strptime(item[0]+\" \"+item[1], \"%m-%d-%Y %H:%M\")\n",
    "                        entry.append((item_f,item[2],item[3]))\n",
    "                    except:\n",
    "                        if(verbose):\n",
    "                            print(f\"\\t[!] Entry {item} in file {filename} is NOT vallid. Skipped!\")\n",
    "                        errcount+=1\n",
    "                # add the entry to the dataset\n",
    "                dataset.append(entry)\n",
    "    print(f\"\\tSkipped {errcount} items for formatting issues in data file. {len(dataset)} loaded.\")\n",
    "    return dataset\n",
    "\n",
    "def compute_datasets(dataset:list,observation_window,waiting_window,prediction_window):\n",
    "\n",
    "    dataset_X = []\n",
    "    dataset_Y = []\n",
    "    \n",
    "    dataset_ST = [entry[0][0] for entry in dataset ]\n",
    "\n",
    "    count_excluded=0\n",
    "\n",
    "    for i in range(0,len(dataset)):\n",
    "        entry = dataset[i]\n",
    "\n",
    "        end_obs = dataset_ST[i]+observation_window\n",
    "        \n",
    "        start_pred = end_obs + waiting_window\n",
    "        end_pred = start_pred + prediction_window\n",
    "\n",
    "        if end_pred < entry[-1][0]:\n",
    "            entry_X = []\n",
    "            found = 0\n",
    "\n",
    "            for item in entry:\n",
    "                if item[0]>= dataset_ST[i] and item[0]<end_obs:\n",
    "                    entry_X.append(item)\n",
    "                if item[0]>=start_pred and item[0]<end_pred:\n",
    "                    # put Y=1 if it has at least one \"65\" entry\n",
    "                    if (item[1]==\"65\"):\n",
    "                        found = 1\n",
    "            dataset_X.append(entry_X)\n",
    "            dataset_Y.append(found)\n",
    "\n",
    "        else:\n",
    "            count_excluded+=1\n",
    "    \n",
    "    dataset_ST = [entry[0][0] for entry in dataset_X ]\n",
    "    dataset_V = [None]*len(dataset_X)\n",
    "    print(f\"-- DS builder\")\n",
    "    print(f\"\\t{count_excluded} entries unsuitable for selected windows.\")\n",
    "    print(f\"\\tFinal dataset size: {len(dataset_X)}. Classes: {sum(1 for c in dataset_Y if c == 1)}|{sum(1 for c in dataset_Y if c == 0)}, entropy {float(compute_entropy(dataset_Y,0)):4.3}\")    \n",
    "    return dataset_X,dataset_Y,dataset_ST,dataset_V\n",
    "\n",
    "# Quick reload if needed for testing/showcasing purposes\n",
    "def reload_ds():\n",
    "    # prepare\n",
    "    dataset = load_diabetes_dataset(False)\n",
    "    observation_window = timedelta(days=+3)\n",
    "    waiting_window = timedelta(days=+0)\n",
    "    prediction_window = timedelta(days=+10)\n",
    "\n",
    "    dataset_X,dataset_Y, dataset_ST,dataset_V = compute_datasets(dataset,observation_window,waiting_window,prediction_window,)\n",
    "    return dataset_X[:-1],dataset_Y[:-1], dataset_ST[:-1],dataset_V[:-1]\n",
    "# Setting up datasets for Boosting task\n",
    "\n",
    "def reload_boosting():\n",
    "    dataset_X,dataset_Y, dataset_ST,dataset_V = reload_ds()\n",
    "    dataset_Y = [(1 if x==1 else -1) for x in dataset_Y] \n",
    "\n",
    "    return  dataset_X,dataset_Y, dataset_ST,dataset_V\n",
    "#print_dataset_state(dataset_X,dataset_Y,dataset_ST,dataset_V,dataset_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints a table with the number of remaining items, starting time, value if any\n",
    "def print_dataset_state(dataset_X,dataset_Y,dataset_ST,dataset_V,indexes=None):\n",
    "    print(\"--DS state\")\n",
    "    if (indexes and len(indexes)>len(dataset_X)):\n",
    "        indexes=None\n",
    "\n",
    "    # Which items do I print?\n",
    "    if indexes is None:\n",
    "        indexes = range(0,len(dataset_X))\n",
    "    \n",
    "    # Header\n",
    "    print(\"index\\tX\\tY\\tST\\t\\t\\tV\")\n",
    "    # Content\n",
    "    for i in indexes:\n",
    "        uneaten = [entry for entry in dataset_X[i] if entry[0] >= dataset_ST[i]]\n",
    "        print(f\"{i}\\tl.{len(uneaten)}\\t{dataset_Y[i]}\\t{dataset_ST[i]}\\t{dataset_V[i]}\\t\")\n",
    "\n",
    "    # Smol final analysis\n",
    "    print(f\"# entries: {len(dataset_X)}, entropy={float(compute_entropy(dataset_Y)):4.3}\")\n",
    "\n",
    "# Prints a table to show weights (and if weights increase or decrease) for each item and for each iteration, + err/alpha\n",
    "def print_weights_status(training_W,dataset_Y,training_alpha, training_err,range_to_print=None):\n",
    "    \n",
    "    # Which items do I print?\n",
    "    if range_to_print is None:\n",
    "        range_to_print=range(0,len(dataset_Y))\n",
    "\n",
    "\n",
    "    # Header\n",
    "    print(\"i\\t\",end=\"\")\n",
    "    for i in range(0,len(training_W)):\n",
    "        print(f\"w{i}\\t\\t\",end=\"\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    # Content\n",
    "    for item in range_to_print: #each row in the DS\n",
    "        print(f\"{item}\\t\",end=\"\")\n",
    "        for step in range(0,len(training_W)): # each weight\n",
    "            print(f\"{training_W[step][item]:4.2}\",end=\"\")\n",
    "            if step!=0:\n",
    "                andamento = f\"{\"\\x1b[31m↑\\033[0;37m\" if training_W[step-1][item]<training_W[step][item] else \"\\033[0;32m↓\\033[0;37m\"}\"\n",
    "                if training_W[step-1][item]==training_W[step][item]:\n",
    "                    andamento=\"!\"\n",
    "                print(andamento,end=\"\")\n",
    "            print(\"\\t\\t\",end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Final row to display alpha and error\n",
    "    print(\"α\\t\",end=\"\")\n",
    "    for i in range(0,len(training_alpha)):\n",
    "        print(f\"{training_alpha[i]:4.2}\\t\\t\",end=\"\")\n",
    "    print(\"(done)\")    \n",
    "    print(\"err\\t\",end=\"\")\n",
    "    for i in range(0,len(training_err)):\n",
    "        print(f\"{training_err[i]:4.2}\\t\\t\",end=\"\")\n",
    "    print(\"(done)\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted entropy and IG (from professor!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information gain for weighted samples\n",
    "# (weight, label)\n",
    "l = [[(2.3, 1),(4.3, 1), (8.3, 1), (3, -1),( 0.9, 1 ), (99, -1) ],[(99, 1),(8.3, 1), (1.3, -1), (2.3, -1), (9,1)]]\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "\n",
    "\n",
    "def weighted_entropy(lp):\n",
    "    df = pd.DataFrame([{\"w\":x[0], \"l\":x[1]} for x in lp])\n",
    "    try:\n",
    "        return (df.groupby(\"l\").sum() / df[\"w\"].sum())[\"w\"].apply(lambda x: -x * log2(x)).sum(), df[\"w\"].sum()\n",
    "    except:\n",
    "        print(lp)\n",
    "\n",
    "def weighted_ig(split,verbose=False):\n",
    "    e, w = weighted_entropy(split[0] + split[1])\n",
    "    e0, w0  = weighted_entropy(split[0])\n",
    "    e1, w1  = weighted_entropy(split[1])\n",
    "    if verbose:\n",
    "        print(f\"before split: e{e:4.2}, w{w:4.2}\")\n",
    "        print(f\"after split: e0 {e0 :4.2} w0 {w0 :4.2} / e1 {e1 :4.2} w1 {w1 :4.2}\")\n",
    "    return e - (w0 / w) * e0 - (w1 / w) * e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that returns classification \n",
    "def compute_weighted_majority(dataset_Y,weights,indexes,verbose=False):\n",
    "    # Sum weight*prediction\n",
    "    classification=0\n",
    "    for i in indexes:\n",
    "        classification += dataset_Y[i]*weights[i]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"votes for final classification:\",classification/weights[i])\n",
    "\n",
    "    else:\n",
    "        classification = -1 if classification < 0 else 1\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence trunk definition\n",
    "Most of functionality is kept from previous exercise; notable changes are in the \"fit\" function, as tree shape is now predefined and doesn't need recursive construction anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Tree,Node\n",
    "\n",
    "class SequenceTrunk(Tree):\n",
    "\n",
    "    #  -- FUNDAMENTALS\n",
    "\n",
    "    def __init__(self, tree=None, deep=False, node_class=None, identifier=None):\n",
    "        super(SequenceTrunk, self).__init__(tree=tree, deep=deep, node_class=node_class, identifier=identifier)\n",
    "\n",
    "    # Library has a bug that won't show trees correctly unless stdout=False is added.\n",
    "    def display(self):\n",
    "        print(self.show(stdout=False))\n",
    "\n",
    "    #  -- NEW NODE GENERATION\n",
    "\n",
    "    # Let's override original create_node method in order to add new constraints such as child node number and true/false branchs.\n",
    "    # In order to create nodes, however, we'll always use create_node_* functions\n",
    "    def create_node(self, tag=None, identifier=None, parent=None, data=None,branch=None):\n",
    "        \"\"\"\n",
    "        Create a child node for the given @parent node. If ``identifier`` is absent,\n",
    "        a UUID will be generated automatically.\n",
    "        \"\"\"\n",
    "        \n",
    "        new_node = super(SequenceTrunk, self).create_node(tag=tag, parent=parent, data=data)\n",
    "        siblings = super(SequenceTrunk,self).siblings(new_node.identifier)\n",
    "        \n",
    "        if len(super(SequenceTrunk,self).siblings(new_node.identifier))>=2:\n",
    "           raise ValueError(\"Parent node already has maximum number of children\")\n",
    "\n",
    "        if branch in [x.data[\"branch\"] for x in siblings]:\n",
    "           raise ValueError(f\"Parent node already has a {branch} branch\")\n",
    "        \n",
    "        return new_node\n",
    "    \n",
    "    def create_node_event(self,data,parent=None,branch=None,entropy=\"\",size=0,ig=\"\",index=\"\",weight=0.0):\n",
    "        branch_f = \"\" if (branch is None) else str(branch)+\" \"\n",
    "        tag =  f\"\\x1b[32m⬤ {branch_f} ({str(data[1])},{format_timedelta(data[0])})\\x1b[0m - [e={float(entropy):4.2} ig={float(ig):4.2} w={float(weight):4.2}] [n={size}] {index}\"\n",
    "        data = {\"branch\":branch, \"dl\":(data[0],data[1]),\"entropy\":entropy,\"ig\":ig,\"index\":index,\"weights\":weight}\n",
    "\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    def create_node_value(self,label_value,parent=None,branch=None,entropy=\"\",size=0,ig=\"\",index=\"\",weight=0.0):\n",
    "        branch_f = \"\" if (branch is None) else branch+\" \"\n",
    "        tag =  f\"\\x1b[31m■ {branch_f} ({label_value}) \\x1b[0m- [e={float(entropy):2.2} ig={ig:4.2} w={float(weight):4.2}] [n={size}] {index}\"\n",
    "        data = {\"branch\":branch,\"value\":label_value,\"entropy\":entropy,\"index\":index,\"weights\":weight}\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    def create_node_class(self,classification,parent=None,branch=None,entropy=\"\",size=0,index=\"\",weight=0.0):\n",
    "        branch_f = \"\" if (branch is None) else str(branch)+\" \"\n",
    "\n",
    "        tag =  f\"\\x1b[33m◆ {branch_f} {classification} \\x1b[0m- [e={float(entropy):2.2} w={float(weight):4.2}] \\x1b[33m[n={size}]\\x1b[0m - {index}\"\n",
    "\n",
    "        # If the classsification had \"max length reached\", remove the tag from data\n",
    "        if isinstance(classification, str):\n",
    "            classification = int(classification[0])\n",
    "\n",
    "        data = {\"branch\":branch, \"class\":classification,\"entropy\":entropy,\"index\":index,\"weights\":weight}\n",
    "\n",
    "\n",
    "        return     self.create_node(tag,data=data,parent=parent,branch=branch)\n",
    "\n",
    "    #  -- EVENT TESTING\n",
    "\n",
    "    # Given a d,l couple, split the dataset in two + update starting times and dataset values.\n",
    "    def perform_event_test(self,max_dl,indexes,dataset_X,ds_ST,dataset_V,verbose=False):\n",
    "        # divide dataset in t and f...\n",
    "        i_T = []\n",
    "        i_F = []\n",
    "\n",
    "        d,l = max_dl\n",
    "        old_dataset_ST=ds_ST.copy()\n",
    "        new_dataset_ST=ds_ST.copy()\n",
    "        new_dataset_V=dataset_V.copy()\n",
    "        \n",
    "        for i in range(0,len(ds_ST)):\n",
    "            entry = dataset_X[i]\n",
    "            found=False\n",
    "\n",
    "            for item in entry:\n",
    "                #starting from the starting time, see if it exists an item with timestamp < d and label == l\n",
    "                if isinstance(old_dataset_ST[i],list):\n",
    "                    old_dataset_ST[i] = old_dataset_ST[i][0]\n",
    "                    \n",
    "                if isinstance(item[0],tuple):\n",
    "                    item[0] = item[0][0]\n",
    "                    \n",
    "\n",
    "                if(found is False and item[0]>= old_dataset_ST[i] and item[0]<=(old_dataset_ST[i]+d) and item[1]==l ): # If i'm over starting time\n",
    "                    found=True\n",
    "                    #print(\"AAAAAAAAAAAA\")\n",
    "                    new_dataset_ST[i] = item[0]\n",
    "                    new_dataset_V[i] = item[2]\n",
    "                    #print(f\"new: {item[2],item[0]}\")\n",
    "\n",
    "            if(found):\n",
    "                i_T.append(i)\n",
    "            else:\n",
    "                i_F.append(i)\n",
    "                \n",
    "        return i_T,i_F,new_dataset_ST,new_dataset_V\n",
    "\n",
    "    #  -- VALUE TESTING\n",
    "\n",
    "    # Given a d,l couple, split the dataset in two \n",
    "    def __perform_value_test(self,value,dataset_V,indexes=None):\n",
    "        i_T=[]\n",
    "        i_F=[]\n",
    "\n",
    "        if indexes == None:\n",
    "            indexes = range(0,len(dataset_V))\n",
    "\n",
    "        for i in indexes:\n",
    "            if dataset_V[i] <= value:\n",
    "                i_T.append(i)\n",
    "            else:\n",
    "                i_F.append(i)\n",
    "        return i_T,i_F\n",
    "\n",
    "    #  -- FIT ALGORITHM\n",
    "        \n",
    "    def fit(self,d,l,v,dataset_X,dataset_Y,dataset_V,dataset_ST,weights,verbose=False):\n",
    "    # Tree shape is now predefined, so fit algorithm doesn't need to be recursive anymore and it just build the same structure node per node.\n",
    "\n",
    "        self.d = d\n",
    "        self.l = l\n",
    "        self.v = v\n",
    "\n",
    "        # -- ROOT NODE\n",
    "        i_T,i_F = test_event(dataset_X,(d,l),dataset_ST)\n",
    "\n",
    "\n",
    "        # If test didn't divide dataset, this thruple is unusable and no tree is generated.\n",
    "        if len(i_T) == 0 or len(i_F)== 0:\n",
    "            return None\n",
    "\n",
    "        # Otherwise, split dataset and generate root node (event test)\n",
    "        l_T = [(weights[i],dataset_Y[i]) for i in i_T]\n",
    "        l_F = [(weights[i],dataset_Y[i]) for i in i_F]\n",
    "        ig = weighted_ig([l_T,l_F])\n",
    "        parent = self.create_node_event((d,l),None,None,weighted_entropy(l_T+l_F)[0],len(i_T)+len(i_F),ig,\"\",weighted_entropy(l_T+l_F)[1])\n",
    "\n",
    "        # -- FALSE TEST LEAF\n",
    "        \n",
    "        # Find majority class (using weights!) and create root->false->class node.\n",
    "        classification = compute_weighted_majority(dataset_Y,weights,i_F,verbose)\n",
    "        self.create_node_class(classification,parent, \"f\",weighted_entropy(l_F)[0],len(i_F),i_F,weighted_entropy(l_F)[1])\n",
    "        \n",
    "        \n",
    "        # -- TRUE TEST NODE: VALUE TEST\n",
    "        \n",
    "        # Take only items that are true on the event test for following nodes.\n",
    "        new_dataset_V = dataset_V.copy() # python was bugging out a lot, tried this and other fixes, now it works and I'm leaaving this just to be safe\n",
    "        new_dataset_ST = dataset_ST.copy()\n",
    "        _,_,new_dataset_ST,new_dataset_V = self.perform_event_test((d,l),i_T,dataset_X,new_dataset_ST,new_dataset_V)\n",
    "       \n",
    "        # Now separate true event test items based on value test. \n",
    "        ivalue_T, ivalue_F = self.__perform_value_test(v,new_dataset_V,i_T)\n",
    "\n",
    "        # If no split can be found, no tree with predefined structure can be built. Return no tree.\n",
    "        if len(ivalue_T) == 0 or len(ivalue_F) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Else, split the dataset again! \n",
    "        lvalue_T = [(weights[i],dataset_Y[i]) for i in ivalue_T]\n",
    "        lvalue_F = [(weights[i],dataset_Y[i]) for i in ivalue_F]\n",
    "\n",
    "        ig_value = weighted_ig([lvalue_T,lvalue_F])\n",
    "        value_node = self.create_node_value(v,parent,\"t\",weighted_entropy(l_T)[0],len(l_T),ig_value,i_T,weighted_entropy(l_T)[1])\n",
    "\n",
    "        # ---- VALUE LEAVES\n",
    "        classification_value_true = compute_weighted_majority(dataset_Y,weights,ivalue_T,verbose)\n",
    "        classification_value_false = compute_weighted_majority(dataset_Y,weights,ivalue_F,verbose)\n",
    "\n",
    "        self.create_node_class(classification_value_true,value_node, \"t\",weighted_entropy(lvalue_T)[0],len(lvalue_T),ivalue_T,weighted_entropy(lvalue_T)[1])\n",
    "        self.create_node_class(classification_value_false,value_node, \"f\",weighted_entropy(lvalue_F)[0],len(lvalue_F),ivalue_F,weighted_entropy(lvalue_F)[1])\n",
    "\n",
    "        return (new_dataset_ST,new_dataset_V)\n",
    "    \n",
    "    #  -- PREDICT ALGORITHM\n",
    "\n",
    "    def __predict_r(self,entry_X,entry_ST,entry_V,node:Node,verbose=False):\n",
    "\n",
    "        if verbose:\n",
    "            print(node)\n",
    "            \n",
    "        # BASE CASE\n",
    "        \n",
    "        if node.is_leaf():\n",
    "            if verbose:\n",
    "                print(\"end\")\n",
    "            return node.data[\"class\"]\n",
    "\n",
    "\n",
    "        # INDUCTIVE CASE    \n",
    "\n",
    "        children = [self.get_node(x) for x in node.successors(self.identifier)]\n",
    "\n",
    "        if \"dl\" in node.data.keys():\n",
    "            if verbose:\n",
    "                print(\"dl test\")\n",
    "            i_T,i_F,entry_ST,entry_V = self.perform_event_test(node.data[\"dl\"],None,entry_X,entry_ST,entry_V)\n",
    "\n",
    "            branch = \"t\" if i_T else \"f\"\n",
    "            next_node = list(filter(lambda x : x.data[\"branch\"]==branch,children))\n",
    "            next_node = next_node[0]\n",
    "\n",
    "            return self.__predict_r(entry_X,entry_ST,entry_V,next_node)\n",
    "\n",
    "        elif \"value\" in node.data.keys():\n",
    "            if verbose:\n",
    "                print(\"value test\")\n",
    "            try:\n",
    "                i_T,i_F = self.__perform_value_test(node.data[\"value\"],entry_V)\n",
    "            except:\n",
    "                print(node.data)\n",
    "            branch = \"t\" if i_T else \"f\"\n",
    "            next_node = list(filter(lambda x : x.data[\"branch\"]==branch,children))[0]\n",
    "\n",
    "            return self.__predict_r(entry_X,entry_ST,entry_V,next_node)\n",
    "\n",
    "    # Given a list of new entries, computes the prediction and returns it. It also prints the confusion matrix!\n",
    "    def predict(self,entry_X,entry_ST,entry_V,entry_Y=None,verbose=False):\n",
    "        if verbose:\n",
    "            print(\"-- Predict\")\n",
    "        results=[]\n",
    "        root = self.get_node(self.root)\n",
    "\n",
    "\n",
    "        if len(entry_V)==1:\n",
    "            entry_X = [entry_X]\n",
    "            if entry_Y is not None:\n",
    "                entry_Y = [entry_Y]\n",
    "            entry_ST = [entry_ST]\n",
    "            entry_V = [entry_V]\n",
    "            results.append(self.__predict_r(entry_X,entry_ST,entry_V,root,verbose))\n",
    "        else:\n",
    "            for i in range(0,len(entry_ST)):\n",
    "                results.append(self.__predict_r([entry_X[i]],[entry_ST[i]],[entry_V[i]],root,verbose))\n",
    "        \n",
    "        if entry_Y is not None:\n",
    "            if verbose:\n",
    "                tp = sum(1 for x, y in zip(results, entry_Y) if (x == 1 and y==1))\n",
    "                tn = sum(1 for x, y in zip(results, entry_Y) if (x == 0 and y==0))\n",
    "                fp = sum(1 for x, y in zip(results, entry_Y) if (x == 1 and y==0))\n",
    "                fn = sum(1 for x, y in zip(results, entry_Y) if (x == 0 and y==1))\n",
    "\n",
    "                print(f\"\\tP\\tN\\nP\\t{tp}\\t{fn}\\nN\\t{fp}\\t{tn}\")\n",
    "                print(f\"Items: {tp+tn+fp+fn}\")\n",
    "                print(f\"Accuracy: {float((tp+tn)/(tp+tn+fp+fn)):4.3}\")\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training script (Boosting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class BoostingClassifier:\n",
    "    # Given a dataset, trains a tree boosting classifier as defined in class.\n",
    "    def train(self,iTERATIONS, how_many_candidates, dataset):\n",
    "        random.seed()\n",
    "        self.iTERATIONS = iTERATIONS # save number of iterations used for training, in order to easily print data later\n",
    "\n",
    "        # Load dataset\n",
    "        dataset_X,dataset_Y, dataset_ST,dataset_V = dataset\n",
    "\n",
    "        # -- INITIALIZATION\n",
    "        # initialize training data\n",
    "        weights = [1/(len(dataset_Y))]*len(dataset_Y)\n",
    "        training_ST = [dataset_ST]\n",
    "        training_V = [dataset_V]\n",
    "        training_alphas = []\n",
    "        training_errors = []\n",
    "        training_phis= []\n",
    "        training_W = [weights]\n",
    "\n",
    "\n",
    "        # -- TRAINING ALGORITHM\n",
    "\n",
    "        for iteration in range(0,iTERATIONS):\n",
    "\n",
    "            # - FIND BEST TREE\n",
    "\n",
    "            # -- 1. Find all possible thruples of l,d,v\n",
    "            candidates = set()\n",
    "            count=0\n",
    "            for entry_i in range(0,len(dataset_X)):\n",
    "                for item in dataset_X[entry_i]:\n",
    "                    if item[0] > training_ST[iteration][entry_i]:\n",
    "                        candidates.add((item[0]-dataset_ST[entry_i],item[1],item[2]))\n",
    "                        count+=1          \n",
    "            candidates = list(random.sample(list(candidates),how_many_candidates)) # I sample candidates because my computer has weak p energy\n",
    "\n",
    "\n",
    "            # -- 2. For each candidate throuple, create sequence trunk and save error\n",
    "            candidate_trees = []\n",
    "            # for each thruple, compute tree\n",
    "            for candidate in candidates:\n",
    "                st = SequenceTrunk()\n",
    "                result = st.fit(candidate[0],candidate[1],candidate[2],dataset_X,dataset_Y,(training_V[iteration]).copy(),(training_ST[iteration]).copy(),training_W[iteration])\n",
    "                if result is not None:\n",
    "                    # Tree was found: compute WEIGHTED tree error\n",
    "                    err=0\n",
    "                    for leaf in st.leaves():\n",
    "                        for i in leaf.data[\"index\"]:\n",
    "                            if not dataset_Y[i] == leaf.data[\"class\"]: # if prediction was wrong add weighted error :)\n",
    "                                err+=weights[i]\n",
    "                    candidate_trees.append((st,err,candidate,result[0],result[1])) \n",
    "                else:\n",
    "                    # Tree was not found: try again with next thruple\n",
    "                    continue\n",
    "            # If it couldn't find even a single tree, quit where you are and save how many iterations you could do before quitting \n",
    "            if len(candidate_trees)==0:\n",
    "                print(\"COULDNT FIND ANY VIABLE TREES IN ITERATION. QUITTING.\")\n",
    "                iTERATIONS=iteration\n",
    "                break\n",
    "\n",
    "\n",
    "            # -- 3. Find best tree for this iteration\n",
    "            min_tuple = min(candidate_trees, key=lambda x: x[1])\n",
    "            err = min_tuple[1]\n",
    "            best_test = min_tuple[2]\n",
    "            best_tree = min_tuple[0]\n",
    "\n",
    "\n",
    "            # - COMPUTE NEW WEIGHTS AND TRAINING VALUES\n",
    "\n",
    "            # -- 1. Alpha\n",
    "            alpha = 0.5 * math.log2((1-err)/err)\n",
    "\n",
    "            # -- 2. Weights\n",
    "            # --- find correct/mistaken items\n",
    "            i_correct = []\n",
    "            i_mistaken = []\n",
    "            for i_entry in range(0,len(dataset_Y)):\n",
    "                for leaf in min_tuple[0].leaves():\n",
    "                    if i_entry in leaf.data[\"index\"]:\n",
    "                        if dataset_Y[i_entry] == leaf.data[\"class\"]:\n",
    "                            i_correct.append(i_entry)\n",
    "                            continue\n",
    "                        else:\n",
    "                            i_mistaken.append(i_entry)\n",
    "            weights_new = [None]*len(dataset_Y)\n",
    "            # --- Assign new weights according to formula\n",
    "            for i in i_mistaken:  \n",
    "                weights_new[i]   =  training_W[iteration][i] * math.sqrt((1-err)/err)\n",
    "            for i in i_correct:\n",
    "                weights_new[i]   =  training_W[iteration][i] * math.sqrt((err)/(1-err))\n",
    "            z = sum(weights_new)\n",
    "            weights_new = [w/z for w in weights_new]\n",
    "\n",
    "            # If Weights stayed the same, something is wrong (weight deltas so wrong that we got over the machine limit... or just bugs in my algorithm)\n",
    "            for i in range(0,len(dataset_Y)):\n",
    "                if weights_new[i] == weights[i]:\n",
    "                    print(\"!!!\")\n",
    "                    break\n",
    "\n",
    "            # - FINALLY: update verything for next step\n",
    "            training_ST.append(min_tuple[3])\n",
    "            training_V.append(min_tuple[4])\n",
    "            training_W.append(weights_new.copy())\n",
    "            training_errors.append(err)\n",
    "            training_alphas.append(alpha)\n",
    "            training_phis.append(best_tree)\n",
    "\n",
    "            print(f\"Iteration {iteration+1}/{iTERATIONS} done!\")\n",
    "\n",
    "\n",
    "        # Tranining is all done: save it all inside the object for further use\n",
    "        self.training_W = training_W\n",
    "        self.training_ST = training_ST\n",
    "        self.training_V = training_V\n",
    "        self.training_alphas = training_alphas\n",
    "        self.training_errors = training_errors\n",
    "        self.training_phis= training_phis\n",
    "        self.training_W = training_W\n",
    "        self.dataset_Y = dataset_Y\n",
    "        self.dataset_X = dataset_X\n",
    "\n",
    "    # Prints a table with weights for all items, and their trend over iterations\n",
    "    def print_weights_status(self):\n",
    "        if not hasattr(self,\"iTERATIONS\"):\n",
    "            print(\"Classifier has not been trained yet!\")\n",
    "            return\n",
    "        print_weights_status(self.training_W,self.dataset_Y,self.training_alphas,self.training_errors)\n",
    "\n",
    "    # Uses a trained sequence trunk booster classifier to predict class for an item or a list of items.\n",
    "    def predict(self,test_X,test_V,test_ST,test_Y,verbose=False):\n",
    "\n",
    "        # The classifier must have been trained\n",
    "        if not hasattr(self,\"iTERATIONS\"):\n",
    "            print(\"Classifier has not been trained yet!\")\n",
    "            return \n",
    "    \n",
    "        # -- 1. First, let's just reuse the tree predict function and let's get simple prediction for all requested items in each iteration.\n",
    "        raw_predictions=[]\n",
    "\n",
    "        # For each tree in classifier, compute predictions and update datasets ST and V\n",
    "        for tree_i in range(0,len(self.training_phis)):\n",
    "            raw_predictions.append(self.training_phis[tree_i].predict(test_X,test_ST,test_V)) #update ST and V each\n",
    "            _,_,test_ST,test_V = self.training_phis[tree_i].perform_event_test((self.training_phis[tree_i].d,self.training_phis[tree_i].l),None,test_X,test_ST,test_V)\n",
    "\n",
    "        # -- 2. Now sum all predictions and apply alphas\n",
    "        weighted_predictions = [0]*len(test_V)\n",
    "        for iteration in range(0,self.iTERATIONS):\n",
    "            for item_i in range(0,len(test_V)):\n",
    "                weighted_predictions[item_i] += self.training_alphas[iteration] * raw_predictions[iteration][item_i]\n",
    "\n",
    "        # -- 3. Cap to 1/-1\n",
    "        weighted_predictions = [-1 if p < 0 else 1 for p in weighted_predictions]\n",
    "\n",
    "        # -- BONUS: CONFORMAL\n",
    "\n",
    "        confidence_levels_t = []\n",
    "        confidence_levels_f = []\n",
    "        for item_i in range(0,len(weighted_predictions)):\n",
    "            confidence = 0\n",
    "            for iteration_i in range(0,len(raw_predictions)):\n",
    "                if raw_predictions[iteration_i][item_i] == weighted_predictions[item_i]:\n",
    "                    confidence+= self.training_alphas[iteration_i]\n",
    "            \n",
    "            if weighted_predictions[item_i] == 1:\n",
    "                confidence_levels_t.append(confidence/sum(self.training_alphas))\n",
    "                confidence_levels_f.append(1-(confidence/sum(self.training_alphas)))\n",
    "            else:\n",
    "                confidence_levels_f.append(confidence/sum(self.training_alphas))\n",
    "                confidence_levels_t.append(1-(confidence/sum(self.training_alphas)))\n",
    "\n",
    "\n",
    "        # Some stats, if you want them\n",
    "        if test_Y is not None:\n",
    "            if verbose:\n",
    "                tp = sum(1 for x, y in zip(weighted_predictions, test_Y) if (x == 1 and y==1))\n",
    "                tn = sum(1 for x, y in zip(weighted_predictions, test_Y) if (x == -1 and y==-1))\n",
    "                fp = sum(1 for x, y in zip(weighted_predictions, test_Y) if (x == 1 and y==-1))\n",
    "                fn = sum(1 for x, y in zip(weighted_predictions, test_Y) if (x == -1 and y==1))\n",
    "\n",
    "                print(f\"\\tP\\tN\\nP\\t{tp}\\t{fn}\\nN\\t{fp}\\t{tn}\")\n",
    "                print(f\"Items: {tp+tn+fp+fn}\")\n",
    "                print(f\"Accuracy: {float((tp+tn)/(tp+tn+fp+fn)):4.3}\")\n",
    "\n",
    "        # All done!\n",
    "        return (weighted_predictions,confidence_levels_t, confidence_levels_f)\n",
    "                \n",
    "    # Computes error variation for each iteration (aka, it inferences using trees [0] and saves error, [0,1] and saves error, ...)\n",
    "    def compute_training_errors(self):\n",
    "\n",
    "        # If tree has not been trained, quit\n",
    "        if not hasattr(self,\"iTERATIONS\"):\n",
    "            print(\"Classifier has not been trained yet!\")\n",
    "            return\n",
    "        \n",
    "        # - COMPUTATION\n",
    "\n",
    "        errs=[]\n",
    "        predictions=[]\n",
    "        # for each tree in classifier, compute predictions\n",
    "        for tree_i in range(0,len(self.training_phis)):\n",
    "            predictions.append(self.training_phis[tree_i].predict(self.dataset_X,self.training_ST[tree_i],self.training_V[tree_i],self.dataset_Y))\n",
    "\n",
    "\n",
    "        # Now, for each iteration compute error to be saved in array\n",
    "        for iteration in range(0,self.iTERATIONS):\n",
    "            count_err = 0\n",
    "            # compute prediction for each item\n",
    "            for item_i in range(0,len(self.dataset_Y)):\n",
    "                # in order to know prediction, compute prediction by sum of prediction of each tree (up to current iteration) * alpha of that iteration\n",
    "                pred=0\n",
    "                for i in range(0,iteration):\n",
    "                    pred += self.training_alphas[i]*predictions[i][item_i]\n",
    "                pred = -1 if pred < 0 else 1\n",
    "                # If prediction was wrong, add error :(\n",
    "                if pred != self.dataset_Y[item_i]:\n",
    "                    count_err+=1\n",
    "            # convert error to percentage\n",
    "            err = count_err/len(self.dataset_Y)\n",
    "            # save error\n",
    "            errs.append(err)\n",
    "        # save prediction errors into object just in case\n",
    "        self.prediction_errors = errs\n",
    "        return errs\n",
    "    \n",
    "    # Prints a plot that showcases the trend of error with each iteration.\n",
    "    def print_error_trend(self):\n",
    "        plt.figure(figsize=(6,3))  # Width, Height in inches\n",
    "        # Adding labels\n",
    "        plt.xlabel('iterations')\n",
    "        plt.ylabel('alpha/err')\n",
    "        plt.plot(self.training_errors,label=\"error\",color=\"orange\")\n",
    "        plt.plot(self.training_alphas,label=\"alpha\",color=\"green\")\n",
    "        self.compute_training_errors()\n",
    "        plt.plot(self.prediction_errors,label=\"prediction error\",color=\"#cc0000\",linewidth=3)\n",
    "        _ = plt.legend(loc='upper right')\n",
    "        plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "        # Displaying the plot\n",
    "        plt.show()\n",
    "\n",
    "    # Prints two plots, attempting to show in a human-readable way how all weights vary across iterations.\n",
    "    def print_weights_stats(self):\n",
    "        \n",
    "        # 1. Compute range of weights for each iteration\n",
    "\n",
    "        max_weights = []\n",
    "        min_weights = []\n",
    "\n",
    "        for i in range(0,self.iTERATIONS):\n",
    "            max_weights.append(max(self.training_W[i]))\n",
    "            min_weights.append(min(self.training_W[i]))\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "        # 2. Show raw weight trend for all iterations and weights (quite messy!)\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(self.training_W)\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Weights value')\n",
    "        plt.title('Weight evolution over iteration')\n",
    "        plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "        # 3. Show boxplot for each iteration + min/max \n",
    "        plt.figure(figsize=(15,5))  # Width, Height in inches\n",
    "        # Adding labels\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('max/min weight')\n",
    "        plt.title('Box plot of weights per iteration')\n",
    "        plt.plot(min_weights,label=\"min\",color=\"green\",linestyle=\"--\")\n",
    "        plt.plot(max_weights,label=\"max\",color=\"orange\",linestyle=\"--\")\n",
    "        \n",
    "        _ = plt.legend(loc='upper right')\n",
    "        plt.grid(color='grey', linestyle='--', linewidth=.5)\n",
    "\n",
    "\n",
    "        plt.boxplot(self.training_W,labels=list(range(0,len(self.training_W))),positions=range(0,len(self.training_W)),vert=True,sym='.', boxprops=dict(color=\"grey\"), whiskerprops=dict(color=\"grey\"))\n",
    "        # Displaying the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- DS loader\n",
      "\tSkipped 46 items for formatting issues in data file. 70 loaded.\n",
      "-- DS builder\n",
      "\t2 entries unsuitable for selected windows.\n",
      "\tFinal dataset size: 68. Classes: 31|37, entropy 0.994\n",
      "Iteration 1/50 done!\n",
      "Iteration 2/50 done!\n",
      "Iteration 3/50 done!\n",
      "Iteration 4/50 done!\n",
      "Iteration 5/50 done!\n",
      "Iteration 6/50 done!\n",
      "Iteration 7/50 done!\n",
      "Iteration 8/50 done!\n",
      "Iteration 9/50 done!\n",
      "Iteration 10/50 done!\n",
      "Iteration 11/50 done!\n",
      "Iteration 12/50 done!\n",
      "Iteration 13/50 done!\n",
      "Iteration 14/50 done!\n",
      "Iteration 15/50 done!\n",
      "Iteration 16/50 done!\n",
      "Iteration 17/50 done!\n",
      "Iteration 18/50 done!\n",
      "Iteration 19/50 done!\n",
      "Iteration 20/50 done!\n",
      "Iteration 21/50 done!\n",
      "Iteration 22/50 done!\n",
      "Iteration 23/50 done!\n",
      "Iteration 24/50 done!\n",
      "Iteration 25/50 done!\n",
      "Iteration 26/50 done!\n",
      "Iteration 27/50 done!\n",
      "Iteration 28/50 done!\n",
      "Iteration 29/50 done!\n",
      "Iteration 30/50 done!\n",
      "Iteration 31/50 done!\n",
      "Iteration 32/50 done!\n",
      "Iteration 33/50 done!\n",
      "Iteration 34/50 done!\n",
      "Iteration 35/50 done!\n",
      "Iteration 36/50 done!\n",
      "Iteration 37/50 done!\n",
      "Iteration 38/50 done!\n",
      "Iteration 39/50 done!\n",
      "Iteration 40/50 done!\n",
      "Iteration 41/50 done!\n",
      "Iteration 42/50 done!\n",
      "Iteration 43/50 done!\n",
      "Iteration 44/50 done!\n",
      "Iteration 45/50 done!\n",
      "Iteration 46/50 done!\n",
      "Iteration 47/50 done!\n",
      "Iteration 48/50 done!\n",
      "Iteration 49/50 done!\n",
      "Iteration 50/50 done!\n",
      "i\tw0\t\tw1\t\tw2\t\tw3\t\tw4\t\tw5\t\tw6\t\tw7\t\tw8\t\tw9\t\tw10\t\tw11\t\tw12\t\tw13\t\tw14\t\tw15\t\tw16\t\tw17\t\tw18\t\tw19\t\tw20\t\tw21\t\tw22\t\tw23\t\tw24\t\tw25\t\tw26\t\tw27\t\tw28\t\tw29\t\tw30\t\tw31\t\tw32\t\tw33\t\tw34\t\tw35\t\tw36\t\tw37\t\tw38\t\tw39\t\tw40\t\tw41\t\tw42\t\tw43\t\tw44\t\tw45\t\tw46\t\tw47\t\tw48\t\tw49\t\tw50\t\t\n",
      "0\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.17\u001b[31m↑\u001b[0;37m\t\t0.098\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t 0.2\u001b[31m↑\u001b[0;37m\t\t0.32\u001b[31m↑\u001b[0;37m\t\t0.24\u001b[0;32m↓\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.29\u001b[31m↑\u001b[0;37m\t\t0.24\u001b[0;32m↓\u001b[0;37m\t\t0.23\u001b[0;32m↓\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.073\u001b[0;32m↓\u001b[0;37m\t\t0.056\u001b[0;32m↓\u001b[0;37m\t\t0.036\u001b[0;32m↓\u001b[0;37m\t\t0.049\u001b[31m↑\u001b[0;37m\t\t0.066\u001b[31m↑\u001b[0;37m\t\t0.085\u001b[31m↑\u001b[0;37m\t\t0.099\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[31m↑\u001b[0;37m\t\t0.075\u001b[0;32m↓\u001b[0;37m\t\t0.082\u001b[31m↑\u001b[0;37m\t\t0.09\u001b[31m↑\u001b[0;37m\t\t0.078\u001b[0;32m↓\u001b[0;37m\t\t0.085\u001b[31m↑\u001b[0;37m\t\t0.069\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[31m↑\u001b[0;37m\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.09\u001b[31m↑\u001b[0;37m\t\t0.098\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.16\u001b[31m↑\u001b[0;37m\t\t0.24\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.14!\t\t0.18\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.16!\t\t0.16!\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "1\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.044\u001b[0;32m↓\u001b[0;37m\t\t0.04\u001b[0;32m↓\u001b[0;37m\t\t0.025\u001b[0;32m↓\u001b[0;37m\t\t0.022\u001b[0;32m↓\u001b[0;37m\t\t0.019\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[0;32m↓\u001b[0;37m\t\t0.0088\u001b[0;32m↓\u001b[0;37m\t\t0.0069\u001b[0;32m↓\u001b[0;37m\t\t0.0063\u001b[0;32m↓\u001b[0;37m\t\t0.0052\u001b[0;32m↓\u001b[0;37m\t\t0.003\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.00082\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[31m↑\u001b[0;37m\t\t0.0038\u001b[31m↑\u001b[0;37m\t\t0.0048\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.00068\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[31m↑\u001b[0;37m\t\t0.00082\u001b[31m↑\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00083\u001b[0;32m↓\u001b[0;37m\t\t0.00079\u001b[0;32m↓\u001b[0;37m\t\t0.00087\u001b[31m↑\u001b[0;37m\t\t0.00095\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[31m↑\u001b[0;37m\t\t0.00092\u001b[0;32m↓\u001b[0;37m\t\t0.00092\u001b[31m↑\u001b[0;37m\t\t0.00073\u001b[0;32m↓\u001b[0;37m\t\t0.00055\u001b[0;32m↓\u001b[0;37m\t\t0.00033\u001b[0;32m↓\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.00033!\t\t\n",
      "2\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.022\u001b[31m↑\u001b[0;37m\t\t0.03\u001b[31m↑\u001b[0;37m\t\t0.044\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[31m↑\u001b[0;37m\t\t0.036\u001b[0;32m↓\u001b[0;37m\t\t0.055\u001b[31m↑\u001b[0;37m\t\t0.066\u001b[31m↑\u001b[0;37m\t\t0.055\u001b[0;32m↓\u001b[0;37m\t\t0.088\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[31m↑\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.18\u001b[31m↑\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.09\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[0;32m↓\u001b[0;37m\t\t0.047\u001b[0;32m↓\u001b[0;37m\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.088\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[31m↑\u001b[0;37m\t\t0.096\u001b[0;32m↓\u001b[0;37m\t\t0.08\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.098\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.11!\t\t0.15\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.19\u001b[31m↑\u001b[0;37m\t\t0.19!\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.14!\t\t0.14!\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "3\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.22\u001b[31m↑\u001b[0;37m\t\t 0.2\u001b[0;32m↓\u001b[0;37m\t\t0.17\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.22\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[0;32m↓\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.21\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.25\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.084\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t 0.2\u001b[31m↑\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.098\u001b[0;32m↓\u001b[0;37m\t\t0.091\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[31m↑\u001b[0;37m\t\t0.19\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.097\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[31m↑\u001b[0;37m\t\t0.25\u001b[31m↑\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[31m↑\u001b[0;37m\t\t 0.2\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[0;32m↓\u001b[0;37m\t\t0.17\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[31m↑\u001b[0;37m\t\t0.17!\t\t\n",
      "4\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.081\u001b[0;32m↓\u001b[0;37m\t\t0.073\u001b[0;32m↓\u001b[0;37m\t\t0.063\u001b[0;32m↓\u001b[0;37m\t\t0.051\u001b[0;32m↓\u001b[0;37m\t\t0.08\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.094\u001b[0;32m↓\u001b[0;37m\t\t0.055\u001b[0;32m↓\u001b[0;37m\t\t0.042\u001b[0;32m↓\u001b[0;37m\t\t0.066\u001b[31m↑\u001b[0;37m\t\t0.035\u001b[0;32m↓\u001b[0;37m\t\t0.067\u001b[31m↑\u001b[0;37m\t\t0.074\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[31m↑\u001b[0;37m\t\t 0.2\u001b[31m↑\u001b[0;37m\t\t0.29\u001b[31m↑\u001b[0;37m\t\t0.22\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.089\u001b[0;32m↓\u001b[0;37m\t\t0.096\u001b[31m↑\u001b[0;37m\t\t0.079\u001b[0;32m↓\u001b[0;37m\t\t0.045\u001b[0;32m↓\u001b[0;37m\t\t0.049\u001b[31m↑\u001b[0;37m\t\t0.054\u001b[31m↑\u001b[0;37m\t\t0.07\u001b[31m↑\u001b[0;37m\t\t0.067\u001b[0;32m↓\u001b[0;37m\t\t0.054\u001b[0;32m↓\u001b[0;37m\t\t0.052\u001b[0;32m↓\u001b[0;37m\t\t0.057\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[31m↑\u001b[0;37m\t\t0.068\u001b[31m↑\u001b[0;37m\t\t0.06\u001b[0;32m↓\u001b[0;37m\t\t0.06\u001b[31m↑\u001b[0;37m\t\t0.048\u001b[0;32m↓\u001b[0;37m\t\t0.036\u001b[0;32m↓\u001b[0;37m\t\t0.06\u001b[31m↑\u001b[0;37m\t\t0.06\u001b[31m↑\u001b[0;37m\t\t0.051\u001b[0;32m↓\u001b[0;37m\t\t0.059\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[31m↑\u001b[0;37m\t\t0.059!\t\t\n",
      "5\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[31m↑\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0043\u001b[0;32m↓\u001b[0;37m\t\t0.0036\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0025\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.00085\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[0;32m↓\u001b[0;37m\t\t0.00063\u001b[0;32m↓\u001b[0;37m\t\t0.0009\u001b[31m↑\u001b[0;37m\t\t0.00068\u001b[0;32m↓\u001b[0;37m\t\t0.00044\u001b[0;32m↓\u001b[0;37m\t\t0.00041\u001b[0;32m↓\u001b[0;37m\t\t0.00036\u001b[0;32m↓\u001b[0;37m\t\t0.00031\u001b[0;32m↓\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[31m↑\u001b[0;37m\t\t0.00025\u001b[0;32m↓\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00015\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t0.00013\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[31m↑\u001b[0;37m\t\t0.00012\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t9.9e-05\u001b[0;32m↓\u001b[0;37m\t\t7.4e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t3.9e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05!\t\t\n",
      "6\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[31m↑\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0043\u001b[0;32m↓\u001b[0;37m\t\t0.0036\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0025\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.00085\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[0;32m↓\u001b[0;37m\t\t0.00063\u001b[0;32m↓\u001b[0;37m\t\t0.0009\u001b[31m↑\u001b[0;37m\t\t0.00068\u001b[0;32m↓\u001b[0;37m\t\t0.00044\u001b[0;32m↓\u001b[0;37m\t\t0.00041\u001b[0;32m↓\u001b[0;37m\t\t0.00036\u001b[0;32m↓\u001b[0;37m\t\t0.00031\u001b[0;32m↓\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[31m↑\u001b[0;37m\t\t0.00025\u001b[0;32m↓\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00015\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t0.00013\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[31m↑\u001b[0;37m\t\t0.00012\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t9.9e-05\u001b[0;32m↓\u001b[0;37m\t\t7.4e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t3.9e-05\u001b[0;32m↓\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05\u001b[31m↑\u001b[0;37m\t\t4.5e-05!\t\t\n",
      "7\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.017\u001b[31m↑\u001b[0;37m\t\t0.023\u001b[31m↑\u001b[0;37m\t\t0.034\u001b[31m↑\u001b[0;37m\t\t0.048\u001b[31m↑\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.042\u001b[31m↑\u001b[0;37m\t\t0.051\u001b[31m↑\u001b[0;37m\t\t0.072\u001b[31m↑\u001b[0;37m\t\t0.042\u001b[0;32m↓\u001b[0;37m\t\t0.075\u001b[31m↑\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.088\u001b[31m↑\u001b[0;37m\t\t0.072\u001b[0;32m↓\u001b[0;37m\t\t0.07\u001b[0;32m↓\u001b[0;37m\t\t0.049\u001b[0;32m↓\u001b[0;37m\t\t0.043\u001b[0;32m↓\u001b[0;37m\t\t0.037\u001b[0;32m↓\u001b[0;37m\t\t0.022\u001b[0;32m↓\u001b[0;37m\t\t0.017\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.009\u001b[0;32m↓\u001b[0;37m\t\t0.0077\u001b[0;32m↓\u001b[0;37m\t\t0.009\u001b[31m↑\u001b[0;37m\t\t0.0085\u001b[0;32m↓\u001b[0;37m\t\t0.007\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0087\u001b[0;32m↓\u001b[0;37m\t\t0.0083\u001b[0;32m↓\u001b[0;37m\t\t0.0068\u001b[0;32m↓\u001b[0;37m\t\t0.0065\u001b[0;32m↓\u001b[0;37m\t\t0.0062\u001b[0;32m↓\u001b[0;37m\t\t0.0059\u001b[0;32m↓\u001b[0;37m\t\t0.0056\u001b[0;32m↓\u001b[0;37m\t\t0.0066\u001b[31m↑\u001b[0;37m\t\t0.0066!\t\t0.0052\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0065\u001b[31m↑\u001b[0;37m\t\t0.0065!\t\t0.0056\u001b[0;32m↓\u001b[0;37m\t\t0.0064\u001b[31m↑\u001b[0;37m\t\t0.0064!\t\t0.0064!\t\t0.0064\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "8\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.036\u001b[31m↑\u001b[0;37m\t\t0.033\u001b[0;32m↓\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.018\u001b[0;32m↓\u001b[0;37m\t\t0.027\u001b[31m↑\u001b[0;37m\t\t0.022\u001b[0;32m↓\u001b[0;37m\t\t0.035\u001b[31m↑\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.032\u001b[31m↑\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[0;32m↓\u001b[0;37m\t\t0.019\u001b[31m↑\u001b[0;37m\t\t0.0098\u001b[0;32m↓\u001b[0;37m\t\t0.0081\u001b[0;32m↓\u001b[0;37m\t\t0.0089\u001b[31m↑\u001b[0;37m\t\t0.0063\u001b[0;32m↓\u001b[0;37m\t\t0.0083\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.0073\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[31m↑\u001b[0;37m\t\t0.0091\u001b[0;32m↓\u001b[0;37m\t\t0.0078\u001b[0;32m↓\u001b[0;37m\t\t0.0069\u001b[0;32m↓\u001b[0;37m\t\t0.0075\u001b[31m↑\u001b[0;37m\t\t0.0062\u001b[0;32m↓\u001b[0;37m\t\t0.0035\u001b[0;32m↓\u001b[0;37m\t\t0.0038\u001b[31m↑\u001b[0;37m\t\t0.0042\u001b[31m↑\u001b[0;37m\t\t0.0054\u001b[31m↑\u001b[0;37m\t\t0.0052\u001b[0;32m↓\u001b[0;37m\t\t0.0042\u001b[0;32m↓\u001b[0;37m\t\t0.004\u001b[0;32m↓\u001b[0;37m\t\t0.0044\u001b[31m↑\u001b[0;37m\t\t0.0048\u001b[31m↑\u001b[0;37m\t\t0.0053\u001b[31m↑\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0047\u001b[31m↑\u001b[0;37m\t\t0.0037\u001b[0;32m↓\u001b[0;37m\t\t0.0028\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0017!\t\t\n",
      "9\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0082\u001b[31m↑\u001b[0;37m\t\t0.0067\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0082\u001b[0;32m↓\u001b[0;37m\t\t0.0098\u001b[31m↑\u001b[0;37m\t\t0.0081\u001b[0;32m↓\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0083\u001b[31m↑\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.007\u001b[0;32m↓\u001b[0;37m\t\t0.0057\u001b[0;32m↓\u001b[0;37m\t\t0.0064\u001b[31m↑\u001b[0;37m\t\t0.0045\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0033\u001b[0;32m↓\u001b[0;37m\t\t0.0047\u001b[31m↑\u001b[0;37m\t\t0.0036\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00096\u001b[0;32m↓\u001b[0;37m\t\t0.00091\u001b[0;32m↓\u001b[0;37m\t\t0.00081\u001b[0;32m↓\u001b[0;37m\t\t0.00081\u001b[31m↑\u001b[0;37m\t\t0.00064\u001b[0;32m↓\u001b[0;37m\t\t0.00048\u001b[0;32m↓\u001b[0;37m\t\t0.00081\u001b[31m↑\u001b[0;37m\t\t0.00081\u001b[31m↑\u001b[0;37m\t\t0.00069\u001b[0;32m↓\u001b[0;37m\t\t0.0008\u001b[31m↑\u001b[0;37m\t\t0.0008\u001b[31m↑\u001b[0;37m\t\t0.0008\u001b[31m↑\u001b[0;37m\t\t0.0008!\t\t\n",
      "10\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0093\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.0075\u001b[0;32m↓\u001b[0;37m\t\t0.0058\u001b[0;32m↓\u001b[0;37m\t\t0.0054\u001b[0;32m↓\u001b[0;37m\t\t0.0076\u001b[31m↑\u001b[0;37m\t\t0.0044\u001b[0;32m↓\u001b[0;37m\t\t0.0034\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[31m↑\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0037\u001b[31m↑\u001b[0;37m\t\t0.0032\u001b[0;32m↓\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.003\u001b[31m↑\u001b[0;37m\t\t0.0045\u001b[31m↑\u001b[0;37m\t\t0.0041\u001b[0;32m↓\u001b[0;37m\t\t0.0037\u001b[0;32m↓\u001b[0;37m\t\t0.0032\u001b[0;32m↓\u001b[0;37m\t\t0.0037\u001b[31m↑\u001b[0;37m\t\t0.0035\u001b[0;32m↓\u001b[0;37m\t\t0.0029\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[0;32m↓\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[31m↑\u001b[0;37m\t\t0.0015!\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.00086\u001b[0;32m↓\u001b[0;37m\t\t0.00053\u001b[0;32m↓\u001b[0;37m\t\t0.00053!\t\t0.00045\u001b[0;32m↓\u001b[0;37m\t\t0.0004\u001b[0;32m↓\u001b[0;37m\t\t0.0004!\t\t0.0004!\t\t0.0004\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "11\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.016\u001b[31m↑\u001b[0;37m\t\t0.023\u001b[31m↑\u001b[0;37m\t\t0.013\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.017\u001b[31m↑\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.018\u001b[31m↑\u001b[0;37m\t\t0.012\u001b[0;32m↓\u001b[0;37m\t\t0.0064\u001b[0;32m↓\u001b[0;37m\t\t0.0052\u001b[0;32m↓\u001b[0;37m\t\t0.0051\u001b[0;32m↓\u001b[0;37m\t\t0.0036\u001b[0;32m↓\u001b[0;37m\t\t0.0031\u001b[0;32m↓\u001b[0;37m\t\t0.0026\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.00079\u001b[0;32m↓\u001b[0;37m\t\t0.00073\u001b[0;32m↓\u001b[0;37m\t\t0.00098\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[31m↑\u001b[0;37m\t\t0.0015\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.00097\u001b[0;32m↓\u001b[0;37m\t\t0.00093\u001b[0;32m↓\u001b[0;37m\t\t0.00089\u001b[0;32m↓\u001b[0;37m\t\t0.00077\u001b[0;32m↓\u001b[0;37m\t\t0.00084\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[31m↑\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00098\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.0011!\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0023\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0014!\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0016!\t\t0.0016!\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "12\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.022\u001b[31m↑\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.017\u001b[0;32m↓\u001b[0;37m\t\t0.014\u001b[0;32m↓\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.0062\u001b[0;32m↓\u001b[0;37m\t\t0.0057\u001b[0;32m↓\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.00074\u001b[0;32m↓\u001b[0;37m\t\t0.00061\u001b[0;32m↓\u001b[0;37m\t\t0.00059\u001b[0;32m↓\u001b[0;37m\t\t0.00042\u001b[0;32m↓\u001b[0;37m\t\t0.00037\u001b[0;32m↓\u001b[0;37m\t\t0.00031\u001b[0;32m↓\u001b[0;37m\t\t0.00019\u001b[0;32m↓\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t9.2e-05\u001b[0;32m↓\u001b[0;37m\t\t8.5e-05\u001b[0;32m↓\u001b[0;37m\t\t7.6e-05\u001b[0;32m↓\u001b[0;37m\t\t6.5e-05\u001b[0;32m↓\u001b[0;37m\t\t7.6e-05\u001b[31m↑\u001b[0;37m\t\t7.2e-05\u001b[0;32m↓\u001b[0;37m\t\t5.9e-05\u001b[0;32m↓\u001b[0;37m\t\t3.4e-05\u001b[0;32m↓\u001b[0;37m\t\t3.2e-05\u001b[0;32m↓\u001b[0;37m\t\t3.1e-05\u001b[0;32m↓\u001b[0;37m\t\t2.7e-05\u001b[0;32m↓\u001b[0;37m\t\t2.5e-05\u001b[0;32m↓\u001b[0;37m\t\t3.1e-05\u001b[31m↑\u001b[0;37m\t\t3e-05\u001b[0;32m↓\u001b[0;37m\t\t2.8e-05\u001b[0;32m↓\u001b[0;37m\t\t2.7e-05\u001b[0;32m↓\u001b[0;37m\t\t2.6e-05\u001b[0;32m↓\u001b[0;37m\t\t3e-05\u001b[31m↑\u001b[0;37m\t\t3e-05!\t\t2.4e-05\u001b[0;32m↓\u001b[0;37m\t\t1.8e-05\u001b[0;32m↓\u001b[0;37m\t\t1.1e-05\u001b[0;32m↓\u001b[0;37m\t\t1.1e-05!\t\t9.3e-06\u001b[0;32m↓\u001b[0;37m\t\t8.2e-06\u001b[0;32m↓\u001b[0;37m\t\t8.2e-06!\t\t8.2e-06!\t\t8.2e-06\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "13\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0083\u001b[31m↑\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0057\u001b[0;32m↓\u001b[0;37m\t\t0.0089\u001b[31m↑\u001b[0;37m\t\t0.0082\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.0068\u001b[0;32m↓\u001b[0;37m\t\t0.0051\u001b[0;32m↓\u001b[0;37m\t\t0.0035\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.0035\u001b[31m↑\u001b[0;37m\t\t0.0034\u001b[0;32m↓\u001b[0;37m\t\t0.0056\u001b[31m↑\u001b[0;37m\t\t0.005\u001b[0;32m↓\u001b[0;37m\t\t0.0042\u001b[0;32m↓\u001b[0;37m\t\t0.0026\u001b[0;32m↓\u001b[0;37m\t\t0.0045\u001b[31m↑\u001b[0;37m\t\t0.0068\u001b[31m↑\u001b[0;37m\t\t0.0063\u001b[0;32m↓\u001b[0;37m\t\t0.0056\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0056\u001b[31m↑\u001b[0;37m\t\t0.0053\u001b[0;32m↓\u001b[0;37m\t\t0.0044\u001b[0;32m↓\u001b[0;37m\t\t0.0025\u001b[0;32m↓\u001b[0;37m\t\t0.0024\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0026\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[31m↑\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0026\u001b[0;32m↓\u001b[0;37m\t\t0.0025\u001b[0;32m↓\u001b[0;37m\t\t0.0029\u001b[31m↑\u001b[0;37m\t\t0.0029!\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0011!\t\t0.0009\u001b[0;32m↓\u001b[0;37m\t\t0.00079\u001b[0;32m↓\u001b[0;37m\t\t0.00079!\t\t0.00079!\t\t0.00079\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "14\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0093\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.0075\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.0089\u001b[0;32m↓\u001b[0;37m\t\t0.0067\u001b[0;32m↓\u001b[0;37m\t\t0.0045\u001b[0;32m↓\u001b[0;37m\t\t0.0024\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00062\u001b[0;32m↓\u001b[0;37m\t\t0.00047\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[0;32m↓\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[0;32m↓\u001b[0;37m\t\t0.00021\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00023\u001b[0;32m↓\u001b[0;37m\t\t0.00019\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.0001\u001b[0;32m↓\u001b[0;37m\t\t0.0001\u001b[0;32m↓\u001b[0;37m\t\t8.7e-05\u001b[0;32m↓\u001b[0;37m\t\t9.5e-05\u001b[31m↑\u001b[0;37m\t\t7.7e-05\u001b[0;32m↓\u001b[0;37m\t\t8.4e-05\u001b[31m↑\u001b[0;37m\t\t8.1e-05\u001b[0;32m↓\u001b[0;37m\t\t7.7e-05\u001b[0;32m↓\u001b[0;37m\t\t7.3e-05\u001b[0;32m↓\u001b[0;37m\t\t8.6e-05\u001b[31m↑\u001b[0;37m\t\t8.6e-05!\t\t6.8e-05\u001b[0;32m↓\u001b[0;37m\t\t5.1e-05\u001b[0;32m↓\u001b[0;37m\t\t3.1e-05\u001b[0;32m↓\u001b[0;37m\t\t3.1e-05!\t\t2.6e-05\u001b[0;32m↓\u001b[0;37m\t\t2.3e-05\u001b[0;32m↓\u001b[0;37m\t\t2.3e-05!\t\t2.3e-05!\t\t2.3e-05\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "15\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0093\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.0075\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.0089\u001b[0;32m↓\u001b[0;37m\t\t0.0067\u001b[0;32m↓\u001b[0;37m\t\t0.0045\u001b[0;32m↓\u001b[0;37m\t\t0.0024\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00062\u001b[0;32m↓\u001b[0;37m\t\t0.00047\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[0;32m↓\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[0;32m↓\u001b[0;37m\t\t0.00021\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00023\u001b[0;32m↓\u001b[0;37m\t\t0.00019\u001b[0;32m↓\u001b[0;37m\t\t0.00011\u001b[0;32m↓\u001b[0;37m\t\t0.0001\u001b[0;32m↓\u001b[0;37m\t\t0.0001\u001b[0;32m↓\u001b[0;37m\t\t8.7e-05\u001b[0;32m↓\u001b[0;37m\t\t8.3e-05\u001b[0;32m↓\u001b[0;37m\t\t0.0001\u001b[31m↑\u001b[0;37m\t\t9.7e-05\u001b[0;32m↓\u001b[0;37m\t\t9.3e-05\u001b[0;32m↓\u001b[0;37m\t\t8.9e-05\u001b[0;32m↓\u001b[0;37m\t\t8.4e-05\u001b[0;32m↓\u001b[0;37m\t\t9.8e-05\u001b[31m↑\u001b[0;37m\t\t9.8e-05!\t\t7.8e-05\u001b[0;32m↓\u001b[0;37m\t\t5.8e-05\u001b[0;32m↓\u001b[0;37m\t\t3.6e-05\u001b[0;32m↓\u001b[0;37m\t\t3.6e-05!\t\t3e-05\u001b[0;32m↓\u001b[0;37m\t\t2.7e-05\u001b[0;32m↓\u001b[0;37m\t\t2.7e-05!\t\t2.7e-05!\t\t2.7e-05\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "16\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0093\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.0075\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.0089\u001b[0;32m↓\u001b[0;37m\t\t0.0067\u001b[0;32m↓\u001b[0;37m\t\t0.0045\u001b[0;32m↓\u001b[0;37m\t\t0.0024\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[0;32m↓\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00062\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0015\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[31m↑\u001b[0;37m\t\t0.0026\u001b[31m↑\u001b[0;37m\t\t0.003\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[0;32m↓\u001b[0;37m\t\t0.0035\u001b[31m↑\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0023\u001b[31m↑\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0024\u001b[31m↑\u001b[0;37m\t\t0.0024!\t\t0.0032\u001b[31m↑\u001b[0;37m\t\t0.0048\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[0;32m↓\u001b[0;37m\t\t0.0029!\t\t0.0038\u001b[31m↑\u001b[0;37m\t\t0.0033\u001b[0;32m↓\u001b[0;37m\t\t0.0033!\t\t0.0033!\t\t0.0033\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "17\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.044\u001b[0;32m↓\u001b[0;37m\t\t0.052\u001b[31m↑\u001b[0;37m\t\t0.032\u001b[0;32m↓\u001b[0;37m\t\t0.029\u001b[0;32m↓\u001b[0;37m\t\t0.043\u001b[31m↑\u001b[0;37m\t\t0.035\u001b[0;32m↓\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.016\u001b[0;32m↓\u001b[0;37m\t\t0.019\u001b[31m↑\u001b[0;37m\t\t0.027\u001b[31m↑\u001b[0;37m\t\t0.015\u001b[0;32m↓\u001b[0;37m\t\t0.027\u001b[31m↑\u001b[0;37m\t\t0.019\u001b[0;32m↓\u001b[0;37m\t\t0.032\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[31m↑\u001b[0;37m\t\t0.06\u001b[0;32m↓\u001b[0;37m\t\t0.099\u001b[31m↑\u001b[0;37m\t\t0.087\u001b[0;32m↓\u001b[0;37m\t\t0.073\u001b[0;32m↓\u001b[0;37m\t\t0.045\u001b[0;32m↓\u001b[0;37m\t\t0.08\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.098\u001b[0;32m↓\u001b[0;37m\t\t0.084\u001b[0;32m↓\u001b[0;37m\t\t0.098\u001b[31m↑\u001b[0;37m\t\t0.092\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.094\u001b[0;32m↓\u001b[0;37m\t\t0.09\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.097\u001b[0;32m↓\u001b[0;37m\t\t0.092\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.085\u001b[0;32m↓\u001b[0;37m\t\t0.064\u001b[0;32m↓\u001b[0;37m\t\t0.039\u001b[0;32m↓\u001b[0;37m\t\t0.039!\t\t0.033\u001b[0;32m↓\u001b[0;37m\t\t0.038\u001b[31m↑\u001b[0;37m\t\t0.038!\t\t0.038!\t\t0.038\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "18\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.022\u001b[31m↑\u001b[0;37m\t\t0.03\u001b[31m↑\u001b[0;37m\t\t0.044\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[31m↑\u001b[0;37m\t\t0.036\u001b[0;32m↓\u001b[0;37m\t\t0.028\u001b[0;32m↓\u001b[0;37m\t\t0.033\u001b[31m↑\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.016\u001b[0;32m↓\u001b[0;37m\t\t0.028\u001b[31m↑\u001b[0;37m\t\t0.019\u001b[0;32m↓\u001b[0;37m\t\t0.033\u001b[31m↑\u001b[0;37m\t\t0.064\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[31m↑\u001b[0;37m\t\t0.089\u001b[0;32m↓\u001b[0;37m\t\t0.075\u001b[0;32m↓\u001b[0;37m\t\t0.046\u001b[0;32m↓\u001b[0;37m\t\t0.082\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.087\u001b[0;32m↓\u001b[0;37m\t\t0.077\u001b[0;32m↓\u001b[0;37m\t\t0.073\u001b[0;32m↓\u001b[0;37m\t\t0.06\u001b[0;32m↓\u001b[0;37m\t\t0.094\u001b[31m↑\u001b[0;37m\t\t0.09\u001b[0;32m↓\u001b[0;37m\t\t0.086\u001b[0;32m↓\u001b[0;37m\t\t0.074\u001b[0;32m↓\u001b[0;37m\t\t0.071\u001b[0;32m↓\u001b[0;37m\t\t0.087\u001b[31m↑\u001b[0;37m\t\t0.083\u001b[0;32m↓\u001b[0;37m\t\t0.08\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[0;32m↓\u001b[0;37m\t\t0.072\u001b[0;32m↓\u001b[0;37m\t\t0.084\u001b[31m↑\u001b[0;37m\t\t0.084!\t\t0.067\u001b[0;32m↓\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.084\u001b[31m↑\u001b[0;37m\t\t0.084!\t\t0.072\u001b[0;32m↓\u001b[0;37m\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.083!\t\t0.083!\t\t0.083\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "19\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.036\u001b[31m↑\u001b[0;37m\t\t0.033\u001b[0;32m↓\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.018\u001b[0;32m↓\u001b[0;37m\t\t0.016\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[0;32m↓\u001b[0;37m\t\t0.0073\u001b[0;32m↓\u001b[0;37m\t\t0.0056\u001b[0;32m↓\u001b[0;37m\t\t0.0068\u001b[31m↑\u001b[0;37m\t\t0.0056\u001b[0;32m↓\u001b[0;37m\t\t0.0033\u001b[0;32m↓\u001b[0;37m\t\t0.0058\u001b[31m↑\u001b[0;37m\t\t0.0091\u001b[31m↑\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0092\u001b[31m↑\u001b[0;37m\t\t0.01\u001b[31m↑\u001b[0;37m\t\t0.017\u001b[31m↑\u001b[0;37m\t\t0.015\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[0;32m↓\u001b[0;37m\t\t0.018\u001b[31m↑\u001b[0;37m\t\t0.032\u001b[31m↑\u001b[0;37m\t\t0.048\u001b[31m↑\u001b[0;37m\t\t0.066\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[0;32m↓\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.045\u001b[0;32m↓\u001b[0;37m\t\t0.042\u001b[0;32m↓\u001b[0;37m\t\t0.035\u001b[0;32m↓\u001b[0;37m\t\t0.054\u001b[31m↑\u001b[0;37m\t\t0.052\u001b[0;32m↓\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.065\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[31m↑\u001b[0;37m\t\t0.072\u001b[0;32m↓\u001b[0;37m\t\t0.069\u001b[0;32m↓\u001b[0;37m\t\t0.066\u001b[0;32m↓\u001b[0;37m\t\t0.063\u001b[0;32m↓\u001b[0;37m\t\t0.056\u001b[0;32m↓\u001b[0;37m\t\t0.056\u001b[31m↑\u001b[0;37m\t\t0.045\u001b[0;32m↓\u001b[0;37m\t\t0.033\u001b[0;32m↓\u001b[0;37m\t\t0.056\u001b[31m↑\u001b[0;37m\t\t0.056\u001b[31m↑\u001b[0;37m\t\t0.048\u001b[0;32m↓\u001b[0;37m\t\t0.055\u001b[31m↑\u001b[0;37m\t\t0.055\u001b[31m↑\u001b[0;37m\t\t0.055\u001b[31m↑\u001b[0;37m\t\t0.055!\t\t\n",
      "20\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0082\u001b[31m↑\u001b[0;37m\t\t0.0067\u001b[0;32m↓\u001b[0;37m\t\t0.0038\u001b[0;32m↓\u001b[0;37m\t\t0.003\u001b[0;32m↓\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0036\u001b[31m↑\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.00098\u001b[0;32m↓\u001b[0;37m\t\t0.0008\u001b[0;32m↓\u001b[0;37m\t\t0.00089\u001b[31m↑\u001b[0;37m\t\t0.00063\u001b[0;32m↓\u001b[0;37m\t\t0.00083\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[31m↑\u001b[0;37m\t\t0.00064\u001b[0;32m↓\u001b[0;37m\t\t0.00049\u001b[0;32m↓\u001b[0;37m\t\t0.00031\u001b[0;32m↓\u001b[0;37m\t\t0.00043\u001b[31m↑\u001b[0;37m\t\t0.00058\u001b[31m↑\u001b[0;37m\t\t0.00075\u001b[31m↑\u001b[0;37m\t\t0.00066\u001b[0;32m↓\u001b[0;37m\t\t0.00072\u001b[31m↑\u001b[0;37m\t\t0.00089\u001b[31m↑\u001b[0;37m\t\t0.0005\u001b[0;32m↓\u001b[0;37m\t\t0.00055\u001b[31m↑\u001b[0;37m\t\t0.00061\u001b[31m↑\u001b[0;37m\t\t0.00078\u001b[31m↑\u001b[0;37m\t\t0.00086\u001b[31m↑\u001b[0;37m\t\t0.0007\u001b[0;32m↓\u001b[0;37m\t\t0.00076\u001b[31m↑\u001b[0;37m\t\t0.00083\u001b[31m↑\u001b[0;37m\t\t0.00091\u001b[31m↑\u001b[0;37m\t\t0.00099\u001b[31m↑\u001b[0;37m\t\t0.00088\u001b[0;32m↓\u001b[0;37m\t\t0.00088\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0012!\t\t\n",
      "21\t0.033\t\t0.083\u001b[31m↑\u001b[0;37m\t\t0.14\u001b[31m↑\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.22\u001b[31m↑\u001b[0;37m\t\t 0.2\u001b[0;32m↓\u001b[0;37m\t\t0.17\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.22\u001b[31m↑\u001b[0;37m\t\t0.17\u001b[0;32m↓\u001b[0;37m\t\t0.16\u001b[0;32m↓\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.075\u001b[0;32m↓\u001b[0;37m\t\t0.057\u001b[0;32m↓\u001b[0;37m\t\t0.09\u001b[31m↑\u001b[0;37m\t\t0.048\u001b[0;32m↓\u001b[0;37m\t\t0.039\u001b[0;32m↓\u001b[0;37m\t\t0.038\u001b[0;32m↓\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.035\u001b[31m↑\u001b[0;37m\t\t0.045\u001b[31m↑\u001b[0;37m\t\t0.064\u001b[31m↑\u001b[0;37m\t\t0.049\u001b[0;32m↓\u001b[0;37m\t\t0.031\u001b[0;32m↓\u001b[0;37m\t\t0.043\u001b[31m↑\u001b[0;37m\t\t0.058\u001b[31m↑\u001b[0;37m\t\t0.075\u001b[31m↑\u001b[0;37m\t\t0.066\u001b[0;32m↓\u001b[0;37m\t\t0.071\u001b[31m↑\u001b[0;37m\t\t0.089\u001b[31m↑\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.055\u001b[31m↑\u001b[0;37m\t\t0.06\u001b[31m↑\u001b[0;37m\t\t0.078\u001b[31m↑\u001b[0;37m\t\t0.075\u001b[0;32m↓\u001b[0;37m\t\t0.061\u001b[0;32m↓\u001b[0;37m\t\t0.058\u001b[0;32m↓\u001b[0;37m\t\t0.064\u001b[31m↑\u001b[0;37m\t\t0.07\u001b[31m↑\u001b[0;37m\t\t0.076\u001b[31m↑\u001b[0;37m\t\t0.067\u001b[0;32m↓\u001b[0;37m\t\t0.067\u001b[31m↑\u001b[0;37m\t\t0.054\u001b[0;32m↓\u001b[0;37m\t\t0.04\u001b[0;32m↓\u001b[0;37m\t\t0.024\u001b[0;32m↓\u001b[0;37m\t\t0.024\u001b[31m↑\u001b[0;37m\t\t0.031\u001b[31m↑\u001b[0;37m\t\t0.036\u001b[31m↑\u001b[0;37m\t\t0.036\u001b[31m↑\u001b[0;37m\t\t0.036!\t\t0.036\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "22\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[31m↑\u001b[0;37m\t\t0.0093\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.0075\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.024\u001b[31m↑\u001b[0;37m\t\t0.019\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[0;32m↓\u001b[0;37m\t\t0.022\u001b[31m↑\u001b[0;37m\t\t0.042\u001b[31m↑\u001b[0;37m\t\t0.041\u001b[0;32m↓\u001b[0;37m\t\t0.067\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[0;32m↓\u001b[0;37m\t\t0.049\u001b[0;32m↓\u001b[0;37m\t\t0.03\u001b[0;32m↓\u001b[0;37m\t\t0.054\u001b[31m↑\u001b[0;37m\t\t0.081\u001b[31m↑\u001b[0;37m\t\t0.074\u001b[0;32m↓\u001b[0;37m\t\t0.066\u001b[0;32m↓\u001b[0;37m\t\t0.057\u001b[0;32m↓\u001b[0;37m\t\t0.066\u001b[31m↑\u001b[0;37m\t\t0.062\u001b[0;32m↓\u001b[0;37m\t\t0.052\u001b[0;32m↓\u001b[0;37m\t\t0.029\u001b[0;32m↓\u001b[0;37m\t\t0.028\u001b[0;32m↓\u001b[0;37m\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.023\u001b[0;32m↓\u001b[0;37m\t\t0.025\u001b[31m↑\u001b[0;37m\t\t0.031\u001b[31m↑\u001b[0;37m\t\t0.034\u001b[31m↑\u001b[0;37m\t\t0.032\u001b[0;32m↓\u001b[0;37m\t\t0.031\u001b[0;32m↓\u001b[0;37m\t\t0.029\u001b[0;32m↓\u001b[0;37m\t\t0.034\u001b[31m↑\u001b[0;37m\t\t0.034!\t\t0.027\u001b[0;32m↓\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.012\u001b[0;32m↓\u001b[0;37m\t\t0.012!\t\t0.016\u001b[31m↑\u001b[0;37m\t\t0.014\u001b[0;32m↓\u001b[0;37m\t\t0.014!\t\t0.014\u001b[31m↑\u001b[0;37m\t\t0.014\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "23\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.036\u001b[31m↑\u001b[0;37m\t\t0.033\u001b[0;32m↓\u001b[0;37m\t\t0.056\u001b[31m↑\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.074\u001b[31m↑\u001b[0;37m\t\t0.06\u001b[0;32m↓\u001b[0;37m\t\t0.095\u001b[31m↑\u001b[0;37m\t\t0.074\u001b[0;32m↓\u001b[0;37m\t\t0.089\u001b[31m↑\u001b[0;37m\t\t0.073\u001b[0;32m↓\u001b[0;37m\t\t0.042\u001b[0;32m↓\u001b[0;37m\t\t0.075\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.063\u001b[0;32m↓\u001b[0;37m\t\t0.052\u001b[0;32m↓\u001b[0;37m\t\t0.05\u001b[0;32m↓\u001b[0;37m\t\t0.035\u001b[0;32m↓\u001b[0;37m\t\t0.047\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[31m↑\u001b[0;37m\t\t0.084\u001b[31m↑\u001b[0;37m\t\t0.064\u001b[0;32m↓\u001b[0;37m\t\t0.041\u001b[0;32m↓\u001b[0;37m\t\t0.057\u001b[31m↑\u001b[0;37m\t\t0.076\u001b[31m↑\u001b[0;37m\t\t0.098\u001b[31m↑\u001b[0;37m\t\t0.087\u001b[0;32m↓\u001b[0;37m\t\t0.082\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[31m↑\u001b[0;37m\t\t0.16\u001b[31m↑\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.19\u001b[31m↑\u001b[0;37m\t\t0.18\u001b[0;32m↓\u001b[0;37m\t\t0.15\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.14\u001b[0;32m↓\u001b[0;37m\t\t0.13\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.11!\t\t0.087\u001b[0;32m↓\u001b[0;37m\t\t0.065\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.093\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.11!\t\t0.11!\t\t\n",
      "24\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0083\u001b[31m↑\u001b[0;37m\t\t0.012\u001b[31m↑\u001b[0;37m\t\t0.017\u001b[31m↑\u001b[0;37m\t\t0.0099\u001b[0;32m↓\u001b[0;37m\t\t0.015\u001b[31m↑\u001b[0;37m\t\t0.018\u001b[31m↑\u001b[0;37m\t\t0.026\u001b[31m↑\u001b[0;37m\t\t0.015\u001b[0;32m↓\u001b[0;37m\t\t0.027\u001b[31m↑\u001b[0;37m\t\t0.018\u001b[0;32m↓\u001b[0;37m\t\t0.032\u001b[31m↑\u001b[0;37m\t\t0.061\u001b[31m↑\u001b[0;37m\t\t0.059\u001b[0;32m↓\u001b[0;37m\t\t0.098\u001b[31m↑\u001b[0;37m\t\t0.086\u001b[0;32m↓\u001b[0;37m\t\t0.072\u001b[0;32m↓\u001b[0;37m\t\t0.044\u001b[0;32m↓\u001b[0;37m\t\t0.079\u001b[31m↑\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.097\u001b[0;32m↓\u001b[0;37m\t\t0.083\u001b[0;32m↓\u001b[0;37m\t\t0.097\u001b[31m↑\u001b[0;37m\t\t0.091\u001b[0;32m↓\u001b[0;37m\t\t0.076\u001b[0;32m↓\u001b[0;37m\t\t0.12\u001b[31m↑\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[0;32m↓\u001b[0;37m\t\t0.094\u001b[0;32m↓\u001b[0;37m\t\t0.089\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t0.096\u001b[0;32m↓\u001b[0;37m\t\t0.091\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.084\u001b[0;32m↓\u001b[0;37m\t\t0.063\u001b[0;32m↓\u001b[0;37m\t\t0.11\u001b[31m↑\u001b[0;37m\t\t0.11!\t\t0.09\u001b[0;32m↓\u001b[0;37m\t\t 0.1\u001b[31m↑\u001b[0;37m\t\t 0.1!\t\t 0.1!\t\t 0.1\u001b[0;32m↓\u001b[0;37m\t\t\n",
      "25\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.0072\u001b[0;32m↓\u001b[0;37m\t\t0.0062\u001b[0;32m↓\u001b[0;37m\t\t0.0051\u001b[0;32m↓\u001b[0;37m\t\t0.0029\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0027\u001b[31m↑\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0036\u001b[31m↑\u001b[0;37m\t\t0.0027\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.00097\u001b[0;32m↓\u001b[0;37m\t\t0.0008\u001b[0;32m↓\u001b[0;37m\t\t0.00088\u001b[31m↑\u001b[0;37m\t\t0.00062\u001b[0;32m↓\u001b[0;37m\t\t0.00082\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[31m↑\u001b[0;37m\t\t0.00064\u001b[0;32m↓\u001b[0;37m\t\t0.00048\u001b[0;32m↓\u001b[0;37m\t\t0.00031\u001b[0;32m↓\u001b[0;37m\t\t0.00043\u001b[31m↑\u001b[0;37m\t\t0.00058\u001b[31m↑\u001b[0;37m\t\t0.00074\u001b[31m↑\u001b[0;37m\t\t0.00066\u001b[0;32m↓\u001b[0;37m\t\t0.00071\u001b[31m↑\u001b[0;37m\t\t0.00088\u001b[31m↑\u001b[0;37m\t\t0.0005\u001b[0;32m↓\u001b[0;37m\t\t0.00055\u001b[31m↑\u001b[0;37m\t\t0.0006\u001b[31m↑\u001b[0;37m\t\t0.00078\u001b[31m↑\u001b[0;37m\t\t0.00085\u001b[31m↑\u001b[0;37m\t\t0.00069\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[31m↑\u001b[0;37m\t\t0.00083\u001b[31m↑\u001b[0;37m\t\t0.0009\u001b[31m↑\u001b[0;37m\t\t0.00098\u001b[31m↑\u001b[0;37m\t\t0.00087\u001b[0;32m↓\u001b[0;37m\t\t0.00087\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0012!\t\t\n",
      "26\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.013\u001b[31m↑\u001b[0;37m\t\t0.022\u001b[31m↑\u001b[0;37m\t\t0.02\u001b[0;32m↓\u001b[0;37m\t\t0.017\u001b[0;32m↓\u001b[0;37m\t\t0.014\u001b[0;32m↓\u001b[0;37m\t\t0.008\u001b[0;32m↓\u001b[0;37m\t\t0.0062\u001b[0;32m↓\u001b[0;37m\t\t0.0057\u001b[0;32m↓\u001b[0;37m\t\t0.0047\u001b[0;32m↓\u001b[0;37m\t\t0.0075\u001b[31m↑\u001b[0;37m\t\t0.0057\u001b[0;32m↓\u001b[0;37m\t\t0.0038\u001b[0;32m↓\u001b[0;37m\t\t0.002\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0019\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0022\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.00065\u001b[0;32m↓\u001b[0;37m\t\t0.00091\u001b[31m↑\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0014\u001b[0;32m↓\u001b[0;37m\t\t0.0015\u001b[31m↑\u001b[0;37m\t\t0.0019\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[0;32m↓\u001b[0;37m\t\t0.0012\u001b[31m↑\u001b[0;37m\t\t0.0013\u001b[31m↑\u001b[0;37m\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0015\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[31m↑\u001b[0;37m\t\t0.0019\u001b[31m↑\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0018\u001b[0;32m↓\u001b[0;37m\t\t0.0018\u001b[31m↑\u001b[0;37m\t\t0.0025\u001b[31m↑\u001b[0;37m\t\t0.0038\u001b[31m↑\u001b[0;37m\t\t0.0023\u001b[0;32m↓\u001b[0;37m\t\t0.0023\u001b[31m↑\u001b[0;37m\t\t0.0029\u001b[31m↑\u001b[0;37m\t\t0.0026\u001b[0;32m↓\u001b[0;37m\t\t0.0026\u001b[31m↑\u001b[0;37m\t\t0.0026\u001b[31m↑\u001b[0;37m\t\t0.0026!\t\t\n",
      "27\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0013\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0016\u001b[0;32m↓\u001b[0;37m\t\t0.0011\u001b[0;32m↓\u001b[0;37m\t\t0.00057\u001b[0;32m↓\u001b[0;37m\t\t0.00047\u001b[0;32m↓\u001b[0;37m\t\t0.00052\u001b[31m↑\u001b[0;37m\t\t0.00036\u001b[0;32m↓\u001b[0;37m\t\t0.00048\u001b[31m↑\u001b[0;37m\t\t0.00061\u001b[31m↑\u001b[0;37m\t\t0.00037\u001b[0;32m↓\u001b[0;37m\t\t0.00028\u001b[0;32m↓\u001b[0;37m\t\t0.00018\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00034\u001b[31m↑\u001b[0;37m\t\t0.00043\u001b[31m↑\u001b[0;37m\t\t0.00038\u001b[0;32m↓\u001b[0;37m\t\t0.00042\u001b[31m↑\u001b[0;37m\t\t0.00051\u001b[31m↑\u001b[0;37m\t\t0.00029\u001b[0;32m↓\u001b[0;37m\t\t0.00032\u001b[31m↑\u001b[0;37m\t\t0.00035\u001b[31m↑\u001b[0;37m\t\t0.00045\u001b[31m↑\u001b[0;37m\t\t0.0005\u001b[31m↑\u001b[0;37m\t\t0.0004\u001b[0;32m↓\u001b[0;37m\t\t0.00044\u001b[31m↑\u001b[0;37m\t\t0.00048\u001b[31m↑\u001b[0;37m\t\t0.00053\u001b[31m↑\u001b[0;37m\t\t0.00057\u001b[31m↑\u001b[0;37m\t\t0.00051\u001b[0;32m↓\u001b[0;37m\t\t0.00051\u001b[31m↑\u001b[0;37m\t\t0.0007\u001b[31m↑\u001b[0;37m\t\t0.001\u001b[31m↑\u001b[0;37m\t\t0.00064\u001b[0;32m↓\u001b[0;37m\t\t0.00064\u001b[31m↑\u001b[0;37m\t\t0.00082\u001b[31m↑\u001b[0;37m\t\t0.00072\u001b[0;32m↓\u001b[0;37m\t\t0.00072\u001b[31m↑\u001b[0;37m\t\t0.00072\u001b[31m↑\u001b[0;37m\t\t0.00072!\t\t\n",
      "28\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.00099\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[0;32m↓\u001b[0;37m\t\t0.00051\u001b[0;32m↓\u001b[0;37m\t\t0.00027\u001b[0;32m↓\u001b[0;37m\t\t0.00022\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[0;32m↓\u001b[0;37m\t\t0.00023\u001b[31m↑\u001b[0;37m\t\t0.00029\u001b[31m↑\u001b[0;37m\t\t0.00018\u001b[0;32m↓\u001b[0;37m\t\t0.00013\u001b[0;32m↓\u001b[0;37m\t\t8.6e-05\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t0.00016\u001b[31m↑\u001b[0;37m\t\t0.00021\u001b[31m↑\u001b[0;37m\t\t0.00018\u001b[0;32m↓\u001b[0;37m\t\t0.0002\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00015\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[31m↑\u001b[0;37m\t\t0.00022\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00019\u001b[0;32m↓\u001b[0;37m\t\t0.00021\u001b[31m↑\u001b[0;37m\t\t0.00023\u001b[31m↑\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00027\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[0;32m↓\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.0005\u001b[31m↑\u001b[0;37m\t\t0.0003\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[31m↑\u001b[0;37m\t\t0.00039\u001b[31m↑\u001b[0;37m\t\t0.00034\u001b[0;32m↓\u001b[0;37m\t\t0.00034\u001b[31m↑\u001b[0;37m\t\t0.00034\u001b[31m↑\u001b[0;37m\t\t0.00034!\t\t\n",
      "29\t0.033\t\t0.021\u001b[0;32m↓\u001b[0;37m\t\t0.011\u001b[0;32m↓\u001b[0;37m\t\t0.01\u001b[0;32m↓\u001b[0;37m\t\t0.0061\u001b[0;32m↓\u001b[0;37m\t\t0.0055\u001b[0;32m↓\u001b[0;37m\t\t0.0048\u001b[0;32m↓\u001b[0;37m\t\t0.0039\u001b[0;32m↓\u001b[0;37m\t\t0.0022\u001b[0;32m↓\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.0021\u001b[31m↑\u001b[0;37m\t\t0.0017\u001b[0;32m↓\u001b[0;37m\t\t0.00099\u001b[0;32m↓\u001b[0;37m\t\t0.00075\u001b[0;32m↓\u001b[0;37m\t\t0.00051\u001b[0;32m↓\u001b[0;37m\t\t0.00027\u001b[0;32m↓\u001b[0;37m\t\t0.00022\u001b[0;32m↓\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[0;32m↓\u001b[0;37m\t\t0.00023\u001b[31m↑\u001b[0;37m\t\t0.00029\u001b[31m↑\u001b[0;37m\t\t0.00018\u001b[0;32m↓\u001b[0;37m\t\t0.00013\u001b[0;32m↓\u001b[0;37m\t\t8.6e-05\u001b[0;32m↓\u001b[0;37m\t\t0.00012\u001b[31m↑\u001b[0;37m\t\t0.00016\u001b[31m↑\u001b[0;37m\t\t0.00021\u001b[31m↑\u001b[0;37m\t\t0.00018\u001b[0;32m↓\u001b[0;37m\t\t0.0002\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00014\u001b[0;32m↓\u001b[0;37m\t\t0.00015\u001b[31m↑\u001b[0;37m\t\t0.00017\u001b[31m↑\u001b[0;37m\t\t0.00022\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00019\u001b[0;32m↓\u001b[0;37m\t\t0.00021\u001b[31m↑\u001b[0;37m\t\t0.00023\u001b[31m↑\u001b[0;37m\t\t0.00025\u001b[31m↑\u001b[0;37m\t\t0.00027\u001b[31m↑\u001b[0;37m\t\t0.00024\u001b[0;32m↓\u001b[0;37m\t\t0.00024\u001b[31m↑\u001b[0;37m\t\t0.00033\u001b[31m↑\u001b[0;37m\t\t0.0005\u001b[31m↑\u001b[0;37m\t\t0.0003\u001b[0;32m↓\u001b[0;37m\t\t0.0003\u001b[31m↑\u001b[0;37m\t\t0.00039\u001b[31m↑\u001b[0;37m\t\t0.00034\u001b[0;32m↓\u001b[0;37m\t\t0.00034\u001b[31m↑\u001b[0;37m\t\t0.00034\u001b[31m↑\u001b[0;37m\t\t0.00034!\t\t\n",
      "α\t 1.0\t\t0.86\t\t0.19\t\t0.73\t\t0.29\t\t0.39\t\t0.39\t\t0.73\t\t 0.5\t\t0.19\t\t0.39\t\t0.73\t\t0.61\t\t0.61\t\t0.86\t\t0.61\t\t0.096\t\t0.61\t\t0.29\t\t0.29\t\t0.61\t\t0.61\t\t0.61\t\t0.29\t\t0.29\t\t0.29\t\t0.19\t\t0.096\t\t0.29\t\t0.73\t\t0.096\t\t0.096\t\t0.29\t\t0.096\t\t0.29\t\t0.096\t\t0.096\t\t0.096\t\t0.096\t\t0.19\t\t1.6e-16\t\t0.39\t\t 0.5\t\t0.73\t\t1.6e-16\t\t0.29\t\t0.19\t\t1.6e-16\t\t1.6e-16\t\t1.6e-16\t\t(done)\n",
      "err\t 0.2\t\t0.23\t\t0.43\t\t0.27\t\t 0.4\t\t0.37\t\t0.37\t\t0.27\t\t0.33\t\t0.43\t\t0.37\t\t0.27\t\t 0.3\t\t 0.3\t\t0.23\t\t 0.3\t\t0.47\t\t 0.3\t\t 0.4\t\t 0.4\t\t 0.3\t\t 0.3\t\t 0.3\t\t 0.4\t\t 0.4\t\t 0.4\t\t0.43\t\t0.47\t\t 0.4\t\t0.27\t\t0.47\t\t0.47\t\t 0.4\t\t0.47\t\t 0.4\t\t0.47\t\t0.47\t\t0.47\t\t0.47\t\t0.43\t\t 0.5\t\t0.37\t\t0.33\t\t0.27\t\t 0.5\t\t 0.4\t\t0.43\t\t 0.5\t\t 0.5\t\t 0.5\t\t(done)\n"
     ]
    }
   ],
   "source": [
    "boosting_classifier = BoostingClassifier()\n",
    "\n",
    "end_train, end_cal = (30,60)\n",
    "\n",
    "\n",
    "# Train dataset\n",
    "dataset_X,dataset_Y, dataset_ST,dataset_V = reload_boosting()\n",
    "boosting_classifier.train(50,20,(dataset_X[:end_train],dataset_Y[:end_train], dataset_ST[:end_train],dataset_V[:end_train]))\n",
    "boosting_classifier.print_weights_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boosting_classifier.print_error_trend()\n",
    "#boosting_classifier.print_weights_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tP\tN\n",
      "P\t13\t1\n",
      "N\t8\t8\n",
      "Items: 30\n",
      "Accuracy:  0.7\n",
      "[0.5388691989128253, 0.5983836461068341, 0.5724532286873768, 0.5319500479645667, 0.6787924847960551, 0.7074293119367958, 0.7566955084776052, 0.6584583519031214, 0.8122101201772415, 0.7981998338391421, 0.8014471749295081, 0.699841794429021, 0.6762989280781545, 0.5132916163899158, 0.6307660389343321, 0.7503548304705051, 0.571349820353041, 0.629202421597918, 0.6203113750644321, 0.6970736871780663, 0.6588784047041328]\n",
      "[0.7611429464324297, 0.5145179500289236, 0.515701011182974, 0.6005738168834228, 0.6005738168834228, 0.6646348537115407, 0.6351144377779863, 0.8525154376511107, 0.8635811822498048]\n"
     ]
    }
   ],
   "source": [
    "# Predict class for new items\n",
    "pred,conf_t, conf_f = boosting_classifier.predict(dataset_X[end_train:end_cal],dataset_V[end_train:end_cal],dataset_ST[end_train:end_cal],dataset_Y[end_train:end_cal],True)\n",
    "ct = []\n",
    "cf =  []\n",
    "for p_i in range(0,len(pred)):\n",
    "    if pred[p_i] == 1:\n",
    "        ct.append(conf_t[p_i])\n",
    "    if pred[p_i] == -1:\n",
    "        cf.append(conf_f[p_i])\n",
    "nct = sorted([1-c for c in ct])\n",
    "ncf = sorted([1-c for c in cf])\n",
    "print(ct)\n",
    "print(cf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## porca miseria infame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration\n",
    "separation = 34\n",
    "calibration_X, calibration_V, calibration_ST, calibration_Y = (dataset_X[end_train:end_cal],dataset_V[end_train:end_cal],dataset_ST[end_train:end_cal],dataset_Y[end_train:end_cal])\n",
    "\n",
    "\n",
    "conformity_alphas=[]\n",
    "#for item_i in range(0,len(calibration_V)):\n",
    "    #alpha = 1 - h dove h è la probabilità che x sia della classe c."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
